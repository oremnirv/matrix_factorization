{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> PCA </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "We want to find  $max_{u} \\sum_{i}^{N}(x_{i}u)^2) /N $ \n",
       "s.t $||u||=1$ since we pay attention \n",
       "that we are looking for a subspace that charcterizes matrix X. \n",
       "in other words if we find the dimensions with greatest amount of variation in data then \n",
       "we can pick top k to get a subspace. \n",
       "So we need to look on the projection of x on u-axis. \n",
       "by definition the dot product of $x*u$ = $||x||*||U||*cos{\\theta}$.\n",
       "when ||U|| = 1, if we remeber that $cos(\\theta)*|hypotenuse| = |adjacent|$ we get that $x*u$ is the projection of x on u with ||u|| = 1.\n",
       "we need the constraint that ||U|| = 1 (same as to say u*u = 1) to get a unique representation of the subspace.\n",
       "otherwise there are many such Us. \n",
       "finding the maximum under constraints sends us to use lagrange multipliers:\n",
       "We pay attention that $max_{u} \\sum_{i}^{N}(x_{i}u)^2) /N $ = $u^T* (\\sum_{i}^{N} x_{i}*x_{i}^T) *u$\n",
       "we define $\\sum = (\\sum_{i}^{N} x_{i}*x_{i}^T)$\n",
       "so $L(\\lambda, u) = u^T\\sum u - \\lambda(u^T*u - 1)$\n",
       "when equating $dL = 0$ ---> $\\sum *u = \\lambda * u $\n",
       "which means u is an eigenvector of $\\sum$. and $\\lambda$ is an eigenvalue.\n",
       "i.e $\\sum$ only contracts or expamds the space in direction $u_{i}$. "
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "We want to find  $max_{u} \\sum_{i}^{N}(x_{i}u)^2) /N $ \n",
    "s.t $||u||=1$ since we pay attention \n",
    "that we are looking for a subspace that charcterizes matrix X. \n",
    "in other words if we find the dimensions with greatest amount of variation in data then \n",
    "we can pick top k to get a subspace. \n",
    "So we need to look on the projection of x on u-axis. \n",
    "by definition the dot product of $x*u$ = $||x||*||U||*cos{\\theta}$.\n",
    "when ||U|| = 1, if we remeber that $cos(\\theta)*|hypotenuse| = |adjacent|$ we get that $x*u$ is the projection of x on u with ||u|| = 1.\n",
    "we need the constraint that ||U|| = 1 (same as to say u*u = 1) to get a unique representation of the subspace.\n",
    "otherwise there are many such Us. \n",
    "finding the maximum under constraints sends us to use lagrange multipliers:\n",
    "We pay attention that $max_{u} \\sum_{i}^{N}(x_{i}u)^2) /N $ = $u^T* (\\sum_{i}^{N} x_{i}*x_{i}^T) *u$\n",
    "we define $\\sum = (\\sum_{i}^{N} x_{i}*x_{i}^T)$\n",
    "so $L(\\lambda, u) = u^T\\sum u - \\lambda(u^T*u - 1)$\n",
    "when equating $dL = 0$ ---> $\\sum *u = \\lambda * u $\n",
    "which means u is an eigenvector of $\\sum$. and $\\lambda$ is an eigenvalue.\n",
    "i.e $\\sum$ only contracts or expamds the space in direction $u_{i}$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "/Users/omer/Documents/studies/applied_ml/matrix_facto.pdf \n",
    "/Users/omer/Documents/studies/applied_ml/andrew_ng_notes_lec_7_till_lec_15.pdf\n",
    "http://www.deeplearningbook.org/contents/linear_algebra.html#pf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io\n",
    "import csv\n",
    "import datetime\n",
    "import os.path\n",
    "import decimal\n",
    "import time\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat(file_name='/Users/omer/Documents/studies/applied_ml/BRMLtoolkit/data/digit5.mat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_five = data['x']\n",
    "num_five = number_five.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 892)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_five.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11bc3bcd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot some of original images to see how data looks like\n",
    "plt.subplot(3, 2, 1)\n",
    "arr=np.asarray(num_five[:,1].reshape(28,28))\n",
    "plt.imshow(arr, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGUAAABiCAYAAABJeR13AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP2gAW4D+oAJoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bbdd290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if each data point is a column\n",
    "# we want to take the mean and std of columns - i.e. the mean pixel i  over all examples\n",
    "# we then take the SVD of X this time we want the eigen vectors of X*X^T. \n",
    "\n",
    "# if each data point is a row \n",
    "# we want to take the mean and std of rows \n",
    "# we then take the SVD of X this time we want the eigen vectors of X^T*X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_fake_matrix_of_ratings_full(dim_ro, dim_col):\n",
    "    mat = np.random.randint(1, 6, size = (dim_ro, dim_col))\n",
    "    return(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix = gen_fake_matrix_of_ratings_full(500, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_fake_matrix_of_ratings_with_missing(dim_ro, dim_col, percent_miss):\n",
    "    original_mat = np.random.randint(1, 6, size = (dim_ro, dim_col))\n",
    "    mat = original_mat.reshape(-1).astype('float')\n",
    "    num_val_to_repllace = int(float(len(mat)) * percent_miss)\n",
    "    random_cells = np.random.randint(0, len(mat), size = [int(num_val_to_repllace)])\n",
    "    for i in random_cells:\n",
    "        mat[i] = np.nan \n",
    "    return(mat.reshape(-1, dim_col), original_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_shifted_mat_by_mean_n_std(mat):\n",
    "    mean_vec = np.sum(mat, axis = 1) / (float(mat.shape[1]))\n",
    "    shifted_mat = (mat - mean_vec.reshape(-1, 1))\n",
    "    #stand_dev = np.sum(np.square(shifted_mat), axis = 1) / (float(mat.shape[1]) - 1.) \n",
    "    #shifted_mat = shifted_mat / np.sqrt(stand_dev)\n",
    "    return(shifted_mat, mean_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is good for:\n",
    "1. Visualization in low dim\n",
    "\n",
    "2. comparison\n",
    "\n",
    "3. learning \n",
    "\n",
    "4. distance calculations  - In nearest neighbours classification, we need to compute the distance between datapoints. For high-dimensional data computing the squared Euclidean distance between vectors can be expensive, and\n",
    "also sensitive to noise. It is therefore often useful to project the data to a lower dimensional representation. For example, in making a classifier to distinguish between the digit 1 and the digit 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# please insert data s.t each data point is a column\n",
    "def pca(matrix, k_top):\n",
    "    shift_matrix, mean = get_shifted_mat_by_mean_n_std(matrix)\n",
    "    U, D, V = np.linalg.svd(shift_matrix) \n",
    "    basis = U[:, :k_top]\n",
    "    lower_dim_rep = np.matmul(np.transpose(basis), shift_matrix)\n",
    "    return(lower_dim_rep, basis,U, D, V)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a,b,c,d, e = pca(num_five, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 784)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 892)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_five.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reconstruction = np.matmul((b), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10b3b4f90>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.subplot(3, 2, 1)\n",
    "arr=np.asarray(reconstruction[:,10].reshape(28,28))\n",
    "plt.imshow(arr, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGUAAABiCAYAAABJeR13AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEiCiUALE/wECdhqugbZGzQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fef2b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_largest_eigenvalues_to_detrmine_subspace_dim(Diagonal_mat, largest_k):\n",
    "    plt.title('largest k scaled eigenvalues')\n",
    "    y_largest_k = (Diagonal_mat[:largest_k]**2) / (Diagonal_mat[0]**2)\n",
    "    x_lar_k = range(largest_k)\n",
    "    plt.plot(x_lar_k, y_largest_k)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZpZBDnczswxyuJuZZdD/BzNzfQ3w9UwFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ed1e850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_largest_eigenvalues_to_detrmine_subspace_dim(d, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> PCA - with missing values </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "We may pay attenttion that finding the PCA is the same as trying to minimize the squared reconstruction loss. \n",
       "we want to find a basis B and a low dim representation Y such that $X˜B^TY$. If $X^i \\in {R^n}$. \n",
       "lets say we have X with columns corresponding to data points s.t $(X^i)_{784X1}$ \n",
       "we further say that lower dimensional representation is in $R^100$ s.t $Y^i_{100X1}$ so we need $B \\in R^{784X100}$\n",
       "so $x_{11} = B_{11}*Y_{11} + B_{12}*Y_{21}...+ B_{1, 100} * Y_{100, 1}$ \n",
       "$X_{21} = B_{21}*Y_{11} + B_{22}*Y_{21}...+ B_{2, 100} * Y_{100, 1}$...\n",
       "$X_{784,1} = B_{784,1}*Y_{11} + B_{784,2}*Y_{21}...+ B_{784, 100} * Y_{100, 1}$\n",
       "for a single point:\n",
       "$X_{ij} = \\sum_{m=1}^{100} B_{i,m}*Y_{m, j}$\n",
       "and for one column the error is:\n",
       "$\\sum_{i=1}^{784} (X_{i.j} - \\sum_{m=1}^{100} B_{i,m}*Y_{m, j})^2$\n",
       "which means the reconstruction error for $X$ is  \n",
       "$\\sum_{j = 1}^{892}(\\sum_{i=1}^{784} (X_{i.j} - \\sum_{m=1}^{100} B_{i,m}*Y_{m, j})^2)$\n",
       "and minimising the reconstruction error under the constraints we get the same expression as above.\n",
       "\n",
       "We take this idea for matrix completion only we count the squared error \n",
       "only when the value exist in the original matrix."
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "We may pay attenttion that finding the PCA is the same as trying to minimize the squared reconstruction loss. \n",
    "we want to find a basis B and a low dim representation Y such that $X˜B^TY$. If $X^i \\in {R^n}$. \n",
    "lets say we have X with columns corresponding to data points s.t $(X^i)_{784X1}$ \n",
    "we further say that lower dimensional representation is in $R^100$ s.t $Y^i_{100X1}$ so we need $B \\in R^{784X100}$\n",
    "so $x_{11} = B_{11}*Y_{11} + B_{12}*Y_{21}...+ B_{1, 100} * Y_{100, 1}$ \n",
    "$X_{21} = B_{21}*Y_{11} + B_{22}*Y_{21}...+ B_{2, 100} * Y_{100, 1}$...\n",
    "$X_{784,1} = B_{784,1}*Y_{11} + B_{784,2}*Y_{21}...+ B_{784, 100} * Y_{100, 1}$\n",
    "for a single point:\n",
    "$X_{ij} = \\sum_{m=1}^{100} B_{i,m}*Y_{m, j}$\n",
    "and for one column the error is:\n",
    "$\\sum_{i=1}^{784} (X_{i.j} - \\sum_{m=1}^{100} B_{i,m}*Y_{m, j})^2$\n",
    "which means the reconstruction error for $X$ is  \n",
    "$\\sum_{j = 1}^{892}(\\sum_{i=1}^{784} (X_{i.j} - \\sum_{m=1}^{100} B_{i,m}*Y_{m, j})^2)$\n",
    "and minimising the reconstruction error under the constraints we get the same expression as above.\n",
    "\n",
    "We take this idea for matrix completion only we count the squared error \n",
    "only when the value exist in the original matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> PCA - with missing values tensorflow </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_miss_matrix_tr_n_val_idx(miss_matrix, tr_precent, val_precent):\n",
    "    n_items = miss_matrix.shape[1]\n",
    "    idx_col = int(n_items * tr_precent)\n",
    "    tr_matrix = miss_matrix[:, :idx_col]\n",
    "    val_matrix = miss_matrix[:, idx_col:]\n",
    "    \n",
    "    tr_idx = np.concatenate((np.array(np.where(~np.isnan(tr_matrix)))[0].reshape(-1, 1), \n",
    "                np.array(np.where(~np.isnan(tr_matrix)))[1].reshape(-1, 1)), axis = 1)\n",
    "    \n",
    "    tr_num = tr_idx.shape[0]\n",
    "    \n",
    "    val_idx = np.concatenate((np.array(np.where(~np.isnan(val_matrix)))[0].reshape(-1, 1), \n",
    "                np.array(np.where(~np.isnan(val_matrix)))[1].reshape(-1, 1)), axis = 1)\n",
    "    \n",
    "    val_num = val_idx.shape[0]\n",
    "    \n",
    "    return(tr_matrix, tr_idx, tr_num, val_matrix, val_idx, val_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_val_miss_mat(k, iter_num, x): \n",
    "# k - number of folds\n",
    "# iter - iteration number\n",
    "# x - training dataset\n",
    "# RETURNS: new train and validation sets\n",
    "    \n",
    "    val_index = x.shape[1] * iter_num / k\n",
    "    \n",
    "    x_val = range((val_index - x.shape[1] / k), val_index, 1)\n",
    "    \n",
    "    x_tr = np.concatenate([np.array(range(0, (val_index - (x.shape[1] / k)))),np.array(range(val_index, x.shape[1], 1))])\n",
    "\n",
    "    non_nan = np.concatenate((np.where(~np.isnan(x))[0].astype(int).reshape(-1, 1),\n",
    "                np.where(~np.isnan(x))[1].astype(int).reshape(-1, 1)), axis = 1)\n",
    "    \n",
    "    tr_idx = non_nan[np.isin(non_nan[:, 1], x_tr), :]\n",
    "    \n",
    "    num_tr = float(tr_idx.shape[0])\n",
    "    \n",
    "    val_idx = non_nan[np.isin(non_nan[:, 1], x_val), :]\n",
    "    \n",
    "    num_val = float(val_idx.shape[0])\n",
    "    \n",
    "    return(tr_idx, num_tr, val_idx, num_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rand_idx_split(num_obser, tr_abs, val_abs):\n",
    "# randomaly permutate numbers, then split train & test data accordingly. \n",
    "\n",
    "    rand_0_1 = np.random.rand(num_obser, 1)\n",
    "\n",
    "    indices = np.random.permutation(rand_0_1.shape[0])\n",
    "\n",
    "    tr_idx, val_idx = indices[:tr_abs], indices[tr_abs:(num_obser)]\n",
    "\n",
    "    tr_idx, val_idx =np.asarray(sorted(tr_idx)),np.asarray(sorted(val_idx))\n",
    "    return(tr_idx, val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "miss_matrix, true_matrix = gen_fake_matrix_of_ratings_with_missing(500, 2000, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_matrix = true_matrix.astype('float32')\n",
    "m = miss_matrix.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function to get a series of numbers with a set jump between terms. \n",
    "def drange(x, y, jump):\n",
    "  while x < y:\n",
    "    yield float(x)\n",
    "    x += decimal.Decimal(jump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank = [50, 100, 150, 200, 250, 300, 350]\n",
    "n_users = int(miss_matrix.shape[0])\n",
    "n_items = int(miss_matrix.shape[1])\n",
    "lr_rat = 0.0001\n",
    "restored = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_plh():\n",
    "    _idx = tf.placeholder(\"int32\", [None, 2], name  =  'utility_matrix_idx')\n",
    "    _beta = tf.placeholder(\"float32\", [], name = 'regularization')\n",
    "    _num = tf.placeholder(\"float32\", [])\n",
    "    return(_idx, _beta, _num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_vars():    \n",
    "    Y = {'low_m': tf.Variable(tf.random_normal([n_users, _rank], mean=0.0,\n",
    "    stddev=0.1) , name  =  'low_p', validate_shape = False),\n",
    "            'low_b': tf.Variable(tf.random_normal([n_users, 1], mean=0.0,\n",
    "    stddev=0.1), name = 'low_p_b')}\n",
    "\n",
    "    B = {'basis_m': tf.Variable(tf.random_normal([_rank, n_items], mean=0.0,\n",
    "    stddev=0.1), name = 'base', validate_shape = False),\n",
    "            'basis_b': tf.Variable(tf.random_normal([1, n_items], mean=0.0,\n",
    "    stddev=0.1), name = 'base_b')}\n",
    "    return(Y, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# calculate loss\n",
    "def main_network(Y, B, _beta, true_matrix, _num, _idx):\n",
    "    \n",
    "    app_x = tf.matmul((Y['low_m'] + Y['low_b']), \n",
    "                         B['basis_m'] + B['basis_b'])\n",
    "    \n",
    "    _true  =  tf.reshape(tf.gather_nd(params  =  true_matrix,\n",
    "                                indices  = _idx), [-1, 1])\n",
    "\n",
    "    _pred = tf.reshape(tf.gather_nd(app_x, indices = _idx), [-1, 1])\n",
    "        \n",
    "    regularizer_Y  =  tf.nn.l2_loss(tf.abs(Y['low_m']))\n",
    "    regularizer_B  =  tf.nn.l2_loss(tf.abs(B['basis_m']))    \n",
    "    \n",
    "    diff = tf.subtract(_true, _pred)\n",
    "    sq_diff = tf.square(diff)\n",
    "    sum_sq_diff = tf.reduce_sum(sq_diff)\n",
    "    \n",
    "    mse = tf.divide(sum_sq_diff, _num) + _beta * (regularizer_Y + regularizer_B)\n",
    "    \n",
    "    opt = tf.train.GradientDescentOptimizer(learning_rate = lr_rat).minimize(mse)\n",
    "    \n",
    "    # accuracy\n",
    "    rmse = tf.sqrt(tf.divide(sum_sq_diff, _num)) \n",
    "    \n",
    "    return(app_x, mse, opt, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph_init():\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session() \n",
    "    sess.run(init)\n",
    "    return(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tb_summary_init(path, loss_param ,accuracy_param):\n",
    "    logs_path_1  =  os.path.join('./' + path, 'run_%d' % run, 'plot_1')\n",
    "    logs_path_2  =  os.path.join('./' + path, 'run_%d' % run, 'plot_2')\n",
    "    tf.summary.histogram(\"weights_y\", Y['low_m'])\n",
    "    tf.summary.histogram(\"weights_b\", B['basis_m'])\n",
    "    tf.summary.scalar(\"mse\" , loss_param)\n",
    "    tf.summary.scalar(\"rmse\",  accuracy_param)\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    writer_1 = tf.summary.FileWriter(logs_path_1, graph = tf.get_default_graph())\n",
    "    writer_2 = tf.summary.FileWriter(logs_path_2, graph = tf.get_default_graph())\n",
    "    return(summary_op, writer_1, writer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writ_meth_to_csv(full_path):\n",
    "    if(os.path.isfile(full_path  + '_.csv')): \n",
    "        writing_method = 'a'\n",
    "    else:\n",
    "        writing_method = 'wb'\n",
    "    return (writing_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_network(full_path, path, loss_param ,accuracy_param):\n",
    "    summary_op, writer_1, writer_2 = tb_summary_init(path, loss_param, accuracy_param)\n",
    "    saver = tf.train.Saver(write_version = tf.train.SaverDef.V2)\n",
    "    sess = graph_init()\n",
    "    writing_method = writ_meth_to_csv(full_path)\n",
    "    return(saver, summary_op, writer_1, writer_2, writing_method, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_network(full_path, path):\n",
    "    with open(full_path + '_.csv', writing_method) as csvfile:\n",
    "        wr  =  csv.writer(csvfile,  delimiter = '\\t',  lineterminator = '\\n')\n",
    "        wr.writerow(['Run', 'Iteration', \"mse\", \"accuracy\", \"time\", \"beta\", \"factors\" ,\"lr_rat\", \"train/valid\", 'restored'])\n",
    "        \n",
    "        # training parameters\n",
    "        \n",
    "        beta_power = np.asarray(list(drange(-4, 4.25, 0.25)))\n",
    "        beta = (10 ** beta_power).astype('float32')\n",
    "        n_iter = 100000\n",
    "        k = 5 \n",
    "        \n",
    "        for bet in beta:\n",
    "            print ('training for beta = %.4f'% bet)\n",
    "            t0 = time.time()\n",
    "            for iteration in range(int(n_iter)):\n",
    "                for c_val_num in range(1, k + 1):\n",
    "                    tr_idx, _num_t ,val_idx, _num_v = cross_val_miss_mat(k, c_val_num, m)\n",
    "\n",
    "                    if ((iteration + 1) % 100 == 0):\n",
    "                        _mse_val, _rmse_val, summary = sess.run([mse, rmse, summary_op]\n",
    "                      , feed_dict = { _idx : val_idx,\n",
    "                                     _beta: bet,\n",
    "                                     _num: _num_v,\n",
    "                                    })\n",
    "                        writer_2.add_summary(summary, iteration)\n",
    "\n",
    "\n",
    "\n",
    "                        wr.writerow([run, iteration, _mse_val, _rmse_val, str(datetime.datetime.now()), beta, _rank, \n",
    "                             lr_rat, c_val_num, \"valid\", restored])\n",
    "\n",
    "                    _mse_tr, _rmse_tr,  _, summary = sess.run([mse, rmse, opt, summary_op]\n",
    "                  , feed_dict = { _idx : tr_idx, _beta: bet,  _num: _num_t})\n",
    "\n",
    "                    if ((iteration + 1) % 100 == 0):\n",
    "                        t1 = time.time()\n",
    "                        print('cv:', c_val_num,'Iteration', iteration, 'train mse:', _mse_tr,\n",
    "                                 'train rmse:', _rmse_tr)\n",
    "                        print('cv:', c_val_num, 'Iteration', iteration, 'validation mse:', _mse_val,\n",
    "                             'validation rmse:', _rmse_val)\n",
    "                        print(iteration,'iterations took:',  t1 - t0, 'seconds')\n",
    "                        \n",
    "                        writer_1.add_summary(summary, iteration)\n",
    "\n",
    "                        wr.writerow([run, iteration, _mse_tr, _rmse_tr, str(datetime.datetime.now()), beta,\n",
    "                             _rank, lr_rat, c_val_num, \"train\", restored])\n",
    "                        \n",
    "                    if ((iteration + 1) % 100 == 0):\n",
    "                        folder  =  os.path.join('./' + path, 'run_%d' % run, 'iter_%d' % iteration, 'weights')\n",
    "                        save_path  =  saver.save(sess,  folder + '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_path = 'missing_explicit/mat_fact_w_missing_values'\n",
    "path = 'missing_explicit/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for beta = 0.0001\n",
      "('cv:', 1, 'Iteration', 99, 'train mse:', 964.8305, 'train rmse:', 30.96153)\n",
      "('cv:', 1, 'Iteration', 99, 'validation mse:', 917.45013, 'validation rmse:', 30.186686)\n",
      "(99, 'iterations took:', 55.86760187149048, 'seconds')\n",
      "('cv:', 2, 'Iteration', 99, 'train mse:', 937.48926, 'train rmse:', 30.5168)\n",
      "('cv:', 2, 'Iteration', 99, 'validation mse:', 1018.09216, 'validation rmse:', 31.81003)\n",
      "(99, 'iterations took:', 56.26044583320618, 'seconds')\n",
      "('cv:', 3, 'Iteration', 99, 'train mse:', 917.7159, 'train rmse:', 30.191086)\n",
      "('cv:', 3, 'Iteration', 99, 'validation mse:', 1088.6692, 'validation rmse:', 32.900684)\n",
      "(99, 'iterations took:', 56.573187828063965, 'seconds')\n",
      "('cv:', 4, 'Iteration', 99, 'train mse:', 951.5774, 'train rmse:', 30.74676)\n",
      "('cv:', 4, 'Iteration', 99, 'validation mse:', 944.8061, 'validation rmse:', 30.636448)\n",
      "(99, 'iterations took:', 56.87341785430908, 'seconds')\n",
      "('cv:', 5, 'Iteration', 99, 'train mse:', 987.8934, 'train rmse:', 31.33176)\n",
      "('cv:', 5, 'Iteration', 99, 'validation mse:', 790.74255, 'validation rmse:', 28.009434)\n",
      "(99, 'iterations took:', 57.177573919296265, 'seconds')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-33f688fa6ae1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mapp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msaver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriting_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0maccuracy_param\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-b09481f42ac2>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(full_path, path)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mc_val_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                     \u001b[0mtr_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_num_t\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_num_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_miss_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_val_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-3c6dde8a8f4e>\u001b[0m in \u001b[0;36mcross_val_miss_mat\u001b[0;34m(k, iter_num, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 np.where(~np.isnan(x))[1].astype(int).reshape(-1, 1)), axis = 1)\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtr_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_nan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_nan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mnum_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/omer/anaconda2/envs/tensorflow/lib/python2.7/site-packages/numpy/lib/arraysetops.pyc\u001b[0m in \u001b[0;36misin\u001b[0;34m(element, test_elements, assume_unique, invert)\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m     return in1d(element, test_elements, assume_unique=assume_unique,\n\u001b[0;32m--> 587\u001b[0;31m                 invert=invert).reshape(element.shape)\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/omer/anaconda2/envs/tensorflow/lib/python2.7/site-packages/numpy/lib/arraysetops.pyc\u001b[0m in \u001b[0;36min1d\u001b[0;34m(ar1, ar2, assume_unique, invert)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;31m# Otherwise use sorting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0massume_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0mar1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrev_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0mar2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/omer/anaconda2/envs/tensorflow/lib/python2.7/site-packages/numpy/lib/arraysetops.pyc\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid axis kwarg specified for unique'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/omer/anaconda2/envs/tensorflow/lib/python2.7/site-packages/numpy/lib/arraysetops.pyc\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptional_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mergesort'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_index\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'quicksort'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file_l = []\n",
    "for file in os.listdir('./missing_explicit'):\n",
    "    if fnmatch.fnmatch(file, 'run*'):\n",
    "        file_l.append(int(file[-2: ].strip('_'))) \n",
    "run = max(file_l) + 1\n",
    "for _rank in rank:\n",
    "    tf.reset_default_graph()\n",
    "    _idx, _beta, _num = init_plh()\n",
    "    Y, B = init_vars()\n",
    "    app_x, mse, opt, rmse = main_network(Y, B, _beta, true_matrix, _num, _idx)\n",
    "    saver, summary_op, writer_1, writer_2, writing_method, sess = init_network(full_path, path, loss_param = mse ,accuracy_param= rmse)\n",
    "    train_network(full_path, path)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./run_35/iter_199/weights_\n"
     ]
    }
   ],
   "source": [
    "# restore weights\n",
    "restored = True\n",
    "tf.reset_default_graph()\n",
    "matrix, _idx, _beta, _num = init_plh()\n",
    "Y, B = init_vars()\n",
    "app_x, mse_tr, mse_val, opt, rmse_tr, rmse_val = main_network(Y, B, _beta, true_matrix, _num)\n",
    "saver, summary_op, writer_opt, writing_method, sess = init_network()\n",
    "save_MDir = './missing_explicit/run_35/iter_199/'\n",
    "save_model = os.path.join(save_MDir, 'weights_')\n",
    "sess = tf.Session() \n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess = sess, save_path = save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> IMF missing values tensorflow </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_fake_matrix_implicit_full(dim_ro, dim_col):\n",
    "    mat = np.random.choice(np.arange(0, 2), p=[0.7, 0.3], size=(dim_ro, dim_col))\n",
    "    return(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = gen_fake_matrix_implicit_full(20,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_fake_matrix_implicit_confid(dim_ro, dim_col):\n",
    "    mat = np.random.random(dim_ro * dim_col).reshape(dim_ro, dim_col)\n",
    "    return(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = gen_fake_matrix_implicit_confid(20, 100) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_matrix = r.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confidence_matrix = (e * r).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "alpha = [40, 30, 20, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank = [50, 100, 150, 200, 250, 300, 350]\n",
    "n_users = int(true_matrix.shape[0])\n",
    "n_items = int(true_matrix.shape[1])\n",
    "lr_rat = 0.0001\n",
    "restored = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main_network(Y, B, _beta, _alpha, true_matrix, confidence_matrix, _num, _idx):\n",
    "    \n",
    "    app_x = tf.matmul((Y['low_m'] + Y['low_b']), \n",
    "                         B['basis_m'] + B['basis_b'])\n",
    "        \n",
    "    _true  =  tf.reshape(tf.gather_nd(params  =  true_matrix,\n",
    "                                indices  = _idx), [-1, 1])\n",
    "\n",
    "    _pred = tf.reshape(tf.gather_nd(app_x, indices = _idx), [-1, 1])\n",
    "    \n",
    "    confidence_gathered = tf.reshape(tf.gather_nd(confidence_matrix, indices = _idx), [-1, 1])\n",
    "    \n",
    "    \n",
    "    num_u = tf.shape(true_matrix)[0]\n",
    "    num_i = tf.shape(tf.reshape(_pred, [num_u, -1]))[1]\n",
    "\n",
    "    conf = tf.add((_alpha * confidence_gathered),\n",
    "                  tf.reshape(tf.ones(shape=[tf.size(confidence_gathered)]), [-1, 1]))  \n",
    "        \n",
    "    regularizer_Y  =  tf.nn.l2_loss(tf.abs(Y['low_m']))\n",
    "    regularizer_B  =  tf.nn.l2_loss(tf.abs(B['basis_m']))    \n",
    "    \n",
    "    diff = tf.subtract(_true, _pred)\n",
    "    sq_diff = tf.square(diff)\n",
    "    confident_sq_diff = conf * sq_diff\n",
    "    sum_sq_diff = tf.reduce_sum(confident_sq_diff)\n",
    "    \n",
    "    mse = tf.divide(sum_sq_diff, _num) + _beta * (regularizer_Y + regularizer_B)\n",
    "    \n",
    "    opt = tf.train.GradientDescentOptimizer(learning_rate = lr_rat).minimize(mse)\n",
    "    \n",
    "    top_k = tf.to_int32(tf.divide(num_i, tf.constant(4)))\n",
    "    \n",
    "    # only makes sense to use percentile_rank if data is sparse and users watch less than 50% of videos\n",
    "    ordered_list_vals, ordered_list_idx = tf.nn.top_k(tf.reshape(_pred, [-1, num_i]), top_k)\n",
    "    \n",
    "    \n",
    "    \n",
    "    percentiles = (tf.to_float(tf.range(tf.size(ordered_list_idx))) \n",
    "                                     * tf.to_float(tf.divide(1, tf.size(ordered_list_idx))))\n",
    "    \n",
    "    idx_to_gather = tf.concat([tf.reshape(tf.transpose(tf.tile(input = [tf.range(num_u)],\n",
    "    multiples = [top_k, 1])), [-1, 1]), tf.reshape(ordered_list_idx, [-1, 1])], 1)\n",
    "    \n",
    "    r_ui = tf.gather_nd(params= tf.reshape(confidence_gathered, [-1, num_i]), indices= idx_to_gather)\n",
    "    \n",
    "    # accuracy\n",
    "    ranking = tf.divide(tf.reduce_sum(r_ui * percentiles), tf.reduce_sum(r_ui))\n",
    "    \n",
    "    return(mse, opt, ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_network(full_path, path):\n",
    "    with open(full_path  + '_.csv', writing_method) as csvfile:\n",
    "        wr  =  csv.writer(csvfile,  delimiter = '\\t',  lineterminator = '\\n')\n",
    "        wr.writerow(['Run', 'Iteration', \"mse\", \"accuracy\", \"time\", \"beta\", \"alpha\", \"factors\" ,\"lr_rat\", \"train/valid\", 'restored'])\n",
    "\n",
    "        # training parameters\n",
    "\n",
    "        beta_power = np.asarray(list(drange(-4, 4.25, 0.25)))\n",
    "        beta = (10 ** beta_power).astype('float32')\n",
    "        n_iter = 100000\n",
    "        k = 5 \n",
    "\n",
    "        for bet in beta:\n",
    "            print ('training for beta = %.4f'% bet)\n",
    "            t0 = time.time()\n",
    "            for iteration in range(int(n_iter)):\n",
    "                for c_val_num in range(1, k + 1):\n",
    "                    tr_idx, _num_t ,val_idx, _num_v = cross_val_miss_mat(k, c_val_num, true_matrix)\n",
    "\n",
    "                    if ((iteration + 1) % 1000 == 0):\n",
    "                        _mse_val, _ranking_val, summary = sess.run([mse, ranking, summary_op]\n",
    "                      , feed_dict = { _idx : val_idx,\n",
    "                                     _beta: bet,\n",
    "                                     _num: _num_v\n",
    "                                    })\n",
    "                        writer_2.add_summary(summary, iteration)\n",
    "\n",
    "                        wr.writerow([run, iteration, _mse_val, _ranking_val, str(datetime.datetime.now()), bet, _alpha, _rank, \n",
    "                             lr_rat, c_val_num, \"valid\", restored])\n",
    "\n",
    "                    _mse_tr,  _, _ranking, summary = sess.run([mse, opt, ranking, summary_op]\n",
    "                  , feed_dict = { _idx : tr_idx, _beta: bet,  _num: _num_t})\n",
    "\n",
    "                    if ((iteration + 1) % 1000 == 0):\n",
    "                        t1 = time.time()\n",
    "                        print('cv:', c_val_num,'Iteration', iteration, 'train mse:', _mse_tr,\n",
    "                                 'train accuracy:', _ranking)\n",
    "                        print('cv:', c_val_num, 'Iteration', iteration, 'validation mse:', _mse_val,\n",
    "                             'validation accuracy:', _ranking_val)\n",
    "                        print(iteration,'iterations took:',  t1 - t0, 'seconds')\n",
    "\n",
    "                        writer_1.add_summary(summary, iteration)\n",
    "\n",
    "                        wr.writerow([run, iteration, _mse_tr, _ranking, str(datetime.datetime.now()), bet, _alpha,\n",
    "                             _rank, lr_rat, c_val_num, \"train\", restored])\n",
    "\n",
    "                    if ((iteration + 1) % 1000 == 0):\n",
    "                        folder  =  os.path.join('./' + path, 'run_%d' % run, 'iter_%d' % iteration, 'weights')\n",
    "                        save_path  =  saver.save(sess,  folder + '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_path = 'IMF/mat_fact_w_missing_values'\n",
    "path = 'IMF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for beta = 0.0001\n",
      "('cv:', 1, 'Iteration', 999, 'train mse:', 0.68927246, 'train accuracy:', 0.5022397)\n",
      "('cv:', 1, 'Iteration', 999, 'validation mse:', 0.6849707, 'validation accuracy:', 0.5187493)\n",
      "(999, 'iterations took:', 5.4255900382995605, 'seconds')\n",
      "('cv:', 2, 'Iteration', 999, 'train mse:', 0.68704534, 'train accuracy:', 0.49948847)\n",
      "('cv:', 2, 'Iteration', 999, 'validation mse:', 0.6938396, 'validation accuracy:', 0.47070986)\n",
      "(999, 'iterations took:', 5.618096113204956, 'seconds')\n",
      "('cv:', 3, 'Iteration', 999, 'train mse:', 0.69133335, 'train accuracy:', 0.5067416)\n",
      "('cv:', 3, 'Iteration', 999, 'validation mse:', 0.6766597, 'validation accuracy:', 0.50800747)\n",
      "(999, 'iterations took:', 5.979859113693237, 'seconds')\n",
      "('cv:', 4, 'Iteration', 999, 'train mse:', 0.68719286, 'train accuracy:', 0.5070735)\n",
      "('cv:', 4, 'Iteration', 999, 'validation mse:', 0.69319534, 'validation accuracy:', 0.44611314)\n",
      "(999, 'iterations took:', 6.164842128753662, 'seconds')\n",
      "('cv:', 5, 'Iteration', 999, 'train mse:', 0.6871825, 'train accuracy:', 0.5048221)\n",
      "('cv:', 5, 'Iteration', 999, 'validation mse:', 0.6932039, 'validation accuracy:', 0.47458577)\n",
      "(999, 'iterations took:', 6.430027008056641, 'seconds')\n",
      "('cv:', 1, 'Iteration', 1999, 'train mse:', 0.68061316, 'train accuracy:', 0.48060328)\n",
      "('cv:', 1, 'Iteration', 1999, 'validation mse:', 0.6793584, 'validation accuracy:', 0.51308775)\n",
      "(1999, 'iterations took:', 12.106541156768799, 'seconds')\n",
      "('cv:', 2, 'Iteration', 1999, 'train mse:', 0.6797225, 'train accuracy:', 0.48404732)\n",
      "('cv:', 2, 'Iteration', 1999, 'validation mse:', 0.68291587, 'validation accuracy:', 0.46208706)\n",
      "(1999, 'iterations took:', 12.302898168563843, 'seconds')\n"
     ]
    }
   ],
   "source": [
    "file_l = []\n",
    "for file in os.listdir('./IMF'):\n",
    "    if fnmatch.fnmatch(file, 'run*'):\n",
    "        file_l.append(int(file[-2: ].strip('_'))) \n",
    "run = max(file_l) + 1\n",
    "for _rank in rank:\n",
    "    for _alpha in alpha:\n",
    "        tf.reset_default_graph()\n",
    "        _idx, _beta, _num = init_plh()\n",
    "        Y, B = init_vars()\n",
    "        mse, opt, ranking = main_network(Y, B, _beta, _alpha, true_matrix, confidence_matrix, _num, _idx)\n",
    "        saver, summary_op, writer_1, writer_2, writing_method, sess = init_network(full_path, path, mse ,ranking)\n",
    "        train_network(full_path, path)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8bf3ecff1273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Alternating least squares IMF </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_fake_matrix_implicit_full(dim_ro, dim_col):\n",
    "    mat = np.random.choice(np.arange(0, 2), p=[0.7, 0.3], size=(dim_ro, dim_col))\n",
    "    return(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_fake_matrix_implicit_confid(dim_ro, dim_col):\n",
    "    mat = np.random.random(dim_ro * dim_col).reshape(dim_ro, dim_col)\n",
    "    return(mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = gen_fake_matrix_implicit_full(20,100) # 20 users, 100 items\n",
    "\n",
    "e = gen_fake_matrix_implicit_confid(20, 100) * 2\n",
    "\n",
    "true_matrix = r.astype('float32')\n",
    "\n",
    "confidence_matrix = (e * r).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_alpha = 40\n",
    "factors = 50\n",
    "num_users = int(true_matrix.shape[0])\n",
    "num_items = int(true_matrix.shape[1])\n",
    "_beta = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_vars():    \n",
    "    Y = np.random.normal(size= [num_items, factors], loc=0.0,\n",
    "    scale=0.1)\n",
    "\n",
    "    X = np.random.normal(size=[num_users, factors], loc=0.0,\n",
    "    scale=0.1)\n",
    "    \n",
    "    return(Y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_u = {} # user confidence\n",
    "for i in range(num_users):\n",
    "    c_u[i] = np.diag(confidence_matrix[i, :])\n",
    "    \n",
    "c_i = {} # item confidence\n",
    "for i in range(num_items):\n",
    "    c_i[i] = np.diag(confidence_matrix[:, i])\n",
    "    \n",
    "user_prefernces = {}\n",
    "for i in range(num_users):\n",
    "    user_prefernces[i] = true_matrix[i, :]\n",
    "    \n",
    "item_prefernces = {}\n",
    "for i in range(num_items):\n",
    "    item_prefernces[i] = true_matrix[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_updt(i, X, Y):\n",
    "    Y_t_Y = np.matmul(np.transpose(Y), Y)\n",
    "    confid_minus_eye = c_u[i] -  np.eye(np.shape(c_u[i])[0])\n",
    "    Y_t_conf_Y = np.matmul(np.matmul(np.transpose(Y), confid_minus_eye), Y)\n",
    "    first_term = np.linalg.inv(Y_t_Y + Y_t_conf_Y + (_beta * np.eye(np.shape(Y_t_conf_Y)[0])))\n",
    "    second_term = np.matmul(np.matmul(np.transpose(Y), c_u[i]), user_prefernces[i])\n",
    "    X[i, :] = np.matmul(first_term, second_term)\n",
    "    \n",
    "    return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def item_updt(j, X, Y):\n",
    "    X_t_X = np.matmul(np.transpose(X), X)\n",
    "    confid_minus_eye = c_i[j] -  np.eye(np.shape(c_i[j])[0])\n",
    "    X_t_conf_X = np.matmul(np.matmul(np.transpose(X), confid_minus_eye), X)\n",
    "    first_term = np.linalg.inv(X_t_X + X_t_conf_X + (_beta * np.eye(np.shape(X_t_conf_X)[0])))\n",
    "    second_term = np.matmul(np.matmul(np.transpose(X), c_i[j]), item_prefernces[j])\n",
    "    Y[j, :] = np.matmul(first_term, second_term)\n",
    "    \n",
    "    return(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y, X = init_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sweep = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sweep no:', 0, 'mse:', 1374.1385435666637)\n",
      "('sweep no:', 1, 'mse:', 1374.0776463969225)\n",
      "('sweep no:', 2, 'mse:', 1374.0168704232515)\n",
      "('sweep no:', 3, 'mse:', 1373.956266084558)\n",
      "('sweep no:', 4, 'mse:', 1373.8958595313932)\n",
      "('sweep no:', 5, 'mse:', 1373.8356675677232)\n",
      "('sweep no:', 6, 'mse:', 1373.775703287368)\n",
      "('sweep no:', 7, 'mse:', 1373.715978123979)\n",
      "('sweep no:', 8, 'mse:', 1373.6565025812065)\n",
      "('sweep no:', 9, 'mse:', 1373.5972864960145)\n",
      "('sweep no:', 10, 'mse:', 1373.538339143157)\n",
      "('sweep no:', 11, 'mse:', 1373.4796692861555)\n",
      "('sweep no:', 12, 'mse:', 1373.421285210359)\n",
      "('sweep no:', 13, 'mse:', 1373.3631947492363)\n",
      "('sweep no:', 14, 'mse:', 1373.3054053075427)\n",
      "('sweep no:', 15, 'mse:', 1373.247923882438)\n",
      "('sweep no:', 16, 'mse:', 1373.1907570832004)\n",
      "('sweep no:', 17, 'mse:', 1373.1339111494794)\n",
      "('sweep no:', 18, 'mse:', 1373.0773919684198)\n",
      "('sweep no:', 19, 'mse:', 1373.0212050906657)\n",
      "('sweep no:', 20, 'mse:', 1372.9653557452675)\n",
      "('sweep no:', 21, 'mse:', 1372.9098488537622)\n",
      "('sweep no:', 22, 'mse:', 1372.8546890435155)\n",
      "('sweep no:', 23, 'mse:', 1372.7998806598896)\n",
      "('sweep no:', 24, 'mse:', 1372.7454277781858)\n",
      "('sweep no:', 25, 'mse:', 1372.691334214481)\n",
      "('sweep no:', 26, 'mse:', 1372.6376035361955)\n",
      "('sweep no:', 27, 'mse:', 1372.584239071842)\n",
      "('sweep no:', 28, 'mse:', 1372.5312439203794)\n",
      "('sweep no:', 29, 'mse:', 1372.4786209600975)\n",
      "('sweep no:', 30, 'mse:', 1372.4263728569053)\n",
      "('sweep no:', 31, 'mse:', 1372.3745020723609)\n",
      "('sweep no:', 32, 'mse:', 1372.3230108712967)\n",
      "('sweep no:', 33, 'mse:', 1372.2719013289313)\n",
      "('sweep no:', 34, 'mse:', 1372.221175337841)\n",
      "('sweep no:', 35, 'mse:', 1372.170834614504)\n",
      "('sweep no:', 36, 'mse:', 1372.1208807055623)\n",
      "('sweep no:', 37, 'mse:', 1372.0713149938538)\n",
      "('sweep no:', 38, 'mse:', 1372.0221387041881)\n",
      "('sweep no:', 39, 'mse:', 1371.9733529087625)\n",
      "('sweep no:', 40, 'mse:', 1371.9249585325863)\n",
      "('sweep no:', 41, 'mse:', 1371.8769563584897)\n",
      "('sweep no:', 42, 'mse:', 1371.8293470319963)\n",
      "('sweep no:', 43, 'mse:', 1371.7821310660777)\n",
      "('sweep no:', 44, 'mse:', 1371.7353088456882)\n",
      "('sweep no:', 45, 'mse:', 1371.688880632067)\n",
      "('sweep no:', 46, 'mse:', 1371.6428465669865)\n",
      "('sweep no:', 47, 'mse:', 1371.5972066768418)\n",
      "('sweep no:', 48, 'mse:', 1371.5519608765364)\n",
      "('sweep no:', 49, 'mse:', 1371.5071089733274)\n",
      "('sweep no:', 50, 'mse:', 1371.462650670436)\n",
      "('sweep no:', 51, 'mse:', 1371.418585570683)\n",
      "('sweep no:', 52, 'mse:', 1371.3749131798636)\n",
      "('sweep no:', 53, 'mse:', 1371.33163291013)\n",
      "('sweep no:', 54, 'mse:', 1371.2887440832542)\n",
      "('sweep no:', 55, 'mse:', 1371.2462459336489)\n",
      "('sweep no:', 56, 'mse:', 1371.2041376115972)\n",
      "('sweep no:', 57, 'mse:', 1371.1624181860473)\n",
      "('sweep no:', 58, 'mse:', 1371.1210866476217)\n",
      "('sweep no:', 59, 'mse:', 1371.0801419112986)\n",
      "('sweep no:', 60, 'mse:', 1371.0395828192222)\n",
      "('sweep no:', 61, 'mse:', 1370.9994081433192)\n",
      "('sweep no:', 62, 'mse:', 1370.9596165878486)\n",
      "('sweep no:', 63, 'mse:', 1370.9202067919248)\n",
      "('sweep no:', 64, 'mse:', 1370.8811773319537)\n",
      "('sweep no:', 65, 'mse:', 1370.8425267239936)\n",
      "('sweep no:', 66, 'mse:', 1370.8042534260933)\n",
      "('sweep no:', 67, 'mse:', 1370.7663558405209)\n",
      "('sweep no:', 68, 'mse:', 1370.728832315957)\n",
      "('sweep no:', 69, 'mse:', 1370.6916811496303)\n",
      "('sweep no:', 70, 'mse:', 1370.6549005894215)\n",
      "('sweep no:', 71, 'mse:', 1370.6184888358573)\n",
      "('sweep no:', 72, 'mse:', 1370.5824440441127)\n",
      "('sweep no:', 73, 'mse:', 1370.5467643259535)\n",
      "('sweep no:', 74, 'mse:', 1370.5114477515515)\n",
      "('sweep no:', 75, 'mse:', 1370.4764923513728)\n",
      "('sweep no:', 76, 'mse:', 1370.4418961179795)\n",
      "('sweep no:', 77, 'mse:', 1370.407657007706)\n",
      "('sweep no:', 78, 'mse:', 1370.3737729423647)\n",
      "('sweep no:', 79, 'mse:', 1370.340241810988)\n",
      "('sweep no:', 80, 'mse:', 1370.307061471345)\n",
      "('sweep no:', 81, 'mse:', 1370.2742297515135)\n",
      "('sweep no:', 82, 'mse:', 1370.241744451503)\n",
      "('sweep no:', 83, 'mse:', 1370.2096033446346)\n",
      "('sweep no:', 84, 'mse:', 1370.1778041790703)\n",
      "('sweep no:', 85, 'mse:', 1370.1463446792184)\n",
      "('sweep no:', 86, 'mse:', 1370.1152225470657)\n",
      "('sweep no:', 87, 'mse:', 1370.0844354636165)\n",
      "('sweep no:', 88, 'mse:', 1370.053981090096)\n",
      "('sweep no:', 89, 'mse:', 1370.0238570693114)\n",
      "('sweep no:', 90, 'mse:', 1369.9940610268593)\n",
      "('sweep no:', 91, 'mse:', 1369.9645905723096)\n",
      "('sweep no:', 92, 'mse:', 1369.9354433004692)\n",
      "('sweep no:', 93, 'mse:', 1369.906616792398)\n",
      "('sweep no:', 94, 'mse:', 1369.8781086166618)\n",
      "('sweep no:', 95, 'mse:', 1369.8499163303154)\n",
      "('sweep no:', 96, 'mse:', 1369.8220374800308)\n",
      "('sweep no:', 97, 'mse:', 1369.7944696030572)\n",
      "('sweep no:', 98, 'mse:', 1369.7672102282716)\n",
      "('sweep no:', 99, 'mse:', 1369.740256877119)\n",
      "('sweep no:', 100, 'mse:', 1369.7136070645806)\n",
      "('sweep no:', 101, 'mse:', 1369.6872583000766)\n",
      "('sweep no:', 102, 'mse:', 1369.6612080883174)\n",
      "('sweep no:', 103, 'mse:', 1369.6354539302574)\n",
      "('sweep no:', 104, 'mse:', 1369.609993323862)\n",
      "('sweep no:', 105, 'mse:', 1369.5848237649216)\n",
      "('sweep no:', 106, 'mse:', 1369.5599427478812)\n",
      "('sweep no:', 107, 'mse:', 1369.5353477665926)\n",
      "('sweep no:', 108, 'mse:', 1369.511036315015)\n",
      "('sweep no:', 109, 'mse:', 1369.48700588802)\n",
      "('sweep no:', 110, 'mse:', 1369.463253981978)\n",
      "('sweep no:', 111, 'mse:', 1369.439778095558)\n",
      "('sweep no:', 112, 'mse:', 1369.4165757302878)\n",
      "('sweep no:', 113, 'mse:', 1369.3936443911844)\n",
      "('sweep no:', 114, 'mse:', 1369.3709815874392)\n",
      "('sweep no:', 115, 'mse:', 1369.3485848329635)\n",
      "('sweep no:', 116, 'mse:', 1369.3264516469337)\n",
      "('sweep no:', 117, 'mse:', 1369.3045795544244)\n",
      "('sweep no:', 118, 'mse:', 1369.282966086833)\n",
      "('sweep no:', 119, 'mse:', 1369.2616087825181)\n",
      "('sweep no:', 120, 'mse:', 1369.2405051871506)\n",
      "('sweep no:', 121, 'mse:', 1369.2196528543604)\n",
      "('sweep no:', 122, 'mse:', 1369.1990493460496)\n",
      "('sweep no:', 123, 'mse:', 1369.1786922329343)\n",
      "('sweep no:', 124, 'mse:', 1369.1585790949061)\n",
      "('sweep no:', 125, 'mse:', 1369.138707521513)\n",
      "('sweep no:', 126, 'mse:', 1369.1190751122674)\n",
      "('sweep no:', 127, 'mse:', 1369.0996794771188)\n",
      "('sweep no:', 128, 'mse:', 1369.0805182367437)\n",
      "('sweep no:', 129, 'mse:', 1369.0615890229456)\n",
      "('sweep no:', 130, 'mse:', 1369.0428894789738)\n",
      "('sweep no:', 131, 'mse:', 1369.024417259834)\n",
      "('sweep no:', 132, 'mse:', 1369.0061700325793)\n",
      "('sweep no:', 133, 'mse:', 1368.9881454766983)\n",
      "('sweep no:', 134, 'mse:', 1368.9703412842441)\n",
      "('sweep no:', 135, 'mse:', 1368.9527551602425)\n",
      "('sweep no:', 136, 'mse:', 1368.9353848228586)\n",
      "('sweep no:', 137, 'mse:', 1368.9182280036928)\n",
      "('sweep no:', 138, 'mse:', 1368.9012824479723)\n",
      "('sweep no:', 139, 'mse:', 1368.8845459148142)\n",
      "('sweep no:', 140, 'mse:', 1368.86801617737)\n",
      "('sweep no:', 141, 'mse:', 1368.8516910230846)\n",
      "('sweep no:', 142, 'mse:', 1368.8355682538418)\n",
      "('sweep no:', 143, 'mse:', 1368.8196456861842)\n",
      "('sweep no:', 144, 'mse:', 1368.8039211514297)\n",
      "('sweep no:', 145, 'mse:', 1368.788392495838)\n",
      "('sweep no:', 146, 'mse:', 1368.7730575807914)\n",
      "('sweep no:', 147, 'mse:', 1368.7579142828931)\n",
      "('sweep no:', 148, 'mse:', 1368.742960494114)\n",
      "('sweep no:', 149, 'mse:', 1368.7281941219014)\n",
      "('sweep no:', 150, 'mse:', 1368.713613089269)\n",
      "('sweep no:', 151, 'mse:', 1368.6992153349788)\n",
      "('sweep no:', 152, 'mse:', 1368.6849988135182)\n",
      "('sweep no:', 153, 'mse:', 1368.6709614952806)\n",
      "('sweep no:', 154, 'mse:', 1368.6571013665841)\n",
      "('sweep no:', 155, 'mse:', 1368.6434164297675)\n",
      "('sweep no:', 156, 'mse:', 1368.629904703244)\n",
      "('sweep no:', 157, 'mse:', 1368.6165642215808)\n",
      "('sweep no:', 158, 'mse:', 1368.6033930355002)\n",
      "('sweep no:', 159, 'mse:', 1368.5903892119754)\n",
      "('sweep no:', 160, 'mse:', 1368.5775508342147)\n",
      "('sweep no:', 161, 'mse:', 1368.564876001724)\n",
      "('sweep no:', 162, 'mse:', 1368.552362830338)\n",
      "('sweep no:', 163, 'mse:', 1368.5400094521708)\n",
      "('sweep no:', 164, 'mse:', 1368.5278140157473)\n",
      "('sweep no:', 165, 'mse:', 1368.5157746858938)\n",
      "('sweep no:', 166, 'mse:', 1368.503889643779)\n",
      "('sweep no:', 167, 'mse:', 1368.4921570869387)\n",
      "('sweep no:', 168, 'mse:', 1368.4805752292411)\n",
      "('sweep no:', 169, 'mse:', 1368.469142300852)\n",
      "('sweep no:', 170, 'mse:', 1368.4578565482664)\n",
      "('sweep no:', 171, 'mse:', 1368.446716234228)\n",
      "('sweep no:', 172, 'mse:', 1368.435719637758)\n",
      "('sweep no:', 173, 'mse:', 1368.4248650540806)\n",
      "('sweep no:', 174, 'mse:', 1368.4141507945953)\n",
      "('sweep no:', 175, 'mse:', 1368.403575186865)\n",
      "('sweep no:', 176, 'mse:', 1368.3931365745457)\n",
      "('sweep no:', 177, 'mse:', 1368.3828333173199)\n",
      "('sweep no:', 178, 'mse:', 1368.3726637909083)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sweep no:', 179, 'mse:', 1368.3626263869685)\n",
      "('sweep no:', 180, 'mse:', 1368.3527195130584)\n",
      "('sweep no:', 181, 'mse:', 1368.3429415925052)\n",
      "('sweep no:', 182, 'mse:', 1368.3332910644956)\n",
      "('sweep no:', 183, 'mse:', 1368.3237663838913)\n",
      "('sweep no:', 184, 'mse:', 1368.3143660211329)\n",
      "('sweep no:', 185, 'mse:', 1368.3050884623028)\n",
      "('sweep no:', 186, 'mse:', 1368.295932208908)\n",
      "('sweep no:', 187, 'mse:', 1368.2868957779276)\n",
      "('sweep no:', 188, 'mse:', 1368.27797770161)\n",
      "('sweep no:', 189, 'mse:', 1368.2691765275322)\n",
      "('sweep no:', 190, 'mse:', 1368.2604908183885)\n",
      "('sweep no:', 191, 'mse:', 1368.2519191519789)\n",
      "('sweep no:', 192, 'mse:', 1368.2434601211141)\n",
      "('sweep no:', 193, 'mse:', 1368.2351123335116)\n",
      "('sweep no:', 194, 'mse:', 1368.2268744117239)\n",
      "('sweep no:', 195, 'mse:', 1368.2187449930125)\n",
      "('sweep no:', 196, 'mse:', 1368.2107227293031)\n",
      "('sweep no:', 197, 'mse:', 1368.2028062870727)\n",
      "('sweep no:', 198, 'mse:', 1368.1949943472375)\n",
      "('sweep no:', 199, 'mse:', 1368.187285605044)\n",
      "('sweep no:', 200, 'mse:', 1368.1796787700277)\n",
      "('sweep no:', 201, 'mse:', 1368.172172565884)\n",
      "('sweep no:', 202, 'mse:', 1368.1647657303495)\n",
      "('sweep no:', 203, 'mse:', 1368.157457015116)\n",
      "('sweep no:', 204, 'mse:', 1368.1502451857666)\n",
      "('sweep no:', 205, 'mse:', 1368.1431290215705)\n",
      "('sweep no:', 206, 'mse:', 1368.1361073154858)\n",
      "('sweep no:', 207, 'mse:', 1368.129178874002)\n",
      "('sweep no:', 208, 'mse:', 1368.1223425170635)\n",
      "('sweep no:', 209, 'mse:', 1368.1155970779373)\n",
      "('sweep no:', 210, 'mse:', 1368.108941403094)\n",
      "('sweep no:', 211, 'mse:', 1368.1023743521719)\n",
      "('sweep no:', 212, 'mse:', 1368.0958947977686)\n",
      "('sweep no:', 213, 'mse:', 1368.0895016254324)\n",
      "('sweep no:', 214, 'mse:', 1368.083193733469)\n",
      "('sweep no:', 215, 'mse:', 1368.076970032911)\n",
      "('sweep no:', 216, 'mse:', 1368.0708294473397)\n",
      "('sweep no:', 217, 'mse:', 1368.064770912847)\n",
      "('sweep no:', 218, 'mse:', 1368.0587933778359)\n",
      "('sweep no:', 219, 'mse:', 1368.0528958030065)\n",
      "('sweep no:', 220, 'mse:', 1368.0470771611829)\n",
      "('sweep no:', 221, 'mse:', 1368.0413364372607)\n",
      "('sweep no:', 222, 'mse:', 1368.035672628006)\n",
      "('sweep no:', 223, 'mse:', 1368.0300847420492)\n",
      "('sweep no:', 224, 'mse:', 1368.024571799705)\n",
      "('sweep no:', 225, 'mse:', 1368.0191328329163)\n",
      "('sweep no:', 226, 'mse:', 1368.0137668850969)\n",
      "('sweep no:', 227, 'mse:', 1368.008473011061)\n",
      "('sweep no:', 228, 'mse:', 1368.003250276893)\n",
      "('sweep no:', 229, 'mse:', 1367.9980977598243)\n",
      "('sweep no:', 230, 'mse:', 1367.9930145481785)\n",
      "('sweep no:', 231, 'mse:', 1367.9879997412252)\n",
      "('sweep no:', 232, 'mse:', 1367.983052449076)\n",
      "('sweep no:', 233, 'mse:', 1367.9781717925764)\n",
      "('sweep no:', 234, 'mse:', 1367.9733569032016)\n",
      "('sweep no:', 235, 'mse:', 1367.968606922992)\n",
      "('sweep no:', 236, 'mse:', 1367.9639210043622)\n",
      "('sweep no:', 237, 'mse:', 1367.9592983100488)\n",
      "('sweep no:', 238, 'mse:', 1367.9547380130316)\n",
      "('sweep no:', 239, 'mse:', 1367.950239296376)\n",
      "('sweep no:', 240, 'mse:', 1367.945801353145)\n",
      "('sweep no:', 241, 'mse:', 1367.9414233863158)\n",
      "('sweep no:', 242, 'mse:', 1367.9371046086567)\n",
      "('sweep no:', 243, 'mse:', 1367.9328442426267)\n",
      "('sweep no:', 244, 'mse:', 1367.9286415202791)\n",
      "('sweep no:', 245, 'mse:', 1367.9244956831744)\n",
      "('sweep no:', 246, 'mse:', 1367.9204059822384)\n",
      "('sweep no:', 247, 'mse:', 1367.9163716777205)\n",
      "('sweep no:', 248, 'mse:', 1367.912392039029)\n",
      "('sweep no:', 249, 'mse:', 1367.9084663446868)\n",
      "('sweep no:', 250, 'mse:', 1367.9045938821969)\n",
      "('sweep no:', 251, 'mse:', 1367.900773947979)\n",
      "('sweep no:', 252, 'mse:', 1367.8970058472453)\n",
      "('sweep no:', 253, 'mse:', 1367.8932888938962)\n",
      "('sweep no:', 254, 'mse:', 1367.8896224104515)\n",
      "('sweep no:', 255, 'mse:', 1367.8860057279626)\n",
      "('sweep no:', 256, 'mse:', 1367.8824381858778)\n",
      "('sweep no:', 257, 'mse:', 1367.8789191319759)\n",
      "('sweep no:', 258, 'mse:', 1367.8754479222819)\n",
      "('sweep no:', 259, 'mse:', 1367.8720239209326)\n",
      "('sweep no:', 260, 'mse:', 1367.8686465001474)\n",
      "('sweep no:', 261, 'mse:', 1367.865315040079)\n",
      "('sweep no:', 262, 'mse:', 1367.8620289287503)\n",
      "('sweep no:', 263, 'mse:', 1367.8587875620065)\n",
      "('sweep no:', 264, 'mse:', 1367.8555903433114)\n",
      "('sweep no:', 265, 'mse:', 1367.8524366837744)\n",
      "('sweep no:', 266, 'mse:', 1367.8493260020314)\n",
      "('sweep no:', 267, 'mse:', 1367.8462577241082)\n",
      "('sweep no:', 268, 'mse:', 1367.843231283399)\n",
      "('sweep no:', 269, 'mse:', 1367.8402461205558)\n",
      "('sweep no:', 270, 'mse:', 1367.8373016833948)\n",
      "('sweep no:', 271, 'mse:', 1367.834397426829)\n",
      "('sweep no:', 272, 'mse:', 1367.8315328127658)\n",
      "('sweep no:', 273, 'mse:', 1367.8287073100605)\n",
      "('sweep no:', 274, 'mse:', 1367.8259203943767)\n",
      "('sweep no:', 275, 'mse:', 1367.823171548197)\n",
      "('sweep no:', 276, 'mse:', 1367.8204602606233)\n",
      "('sweep no:', 277, 'mse:', 1367.8177860274059)\n",
      "('sweep no:', 278, 'mse:', 1367.8151483508082)\n",
      "('sweep no:', 279, 'mse:', 1367.812546739539)\n",
      "('sweep no:', 280, 'mse:', 1367.8099807086612)\n",
      "('sweep no:', 281, 'mse:', 1367.807449779562)\n",
      "('sweep no:', 282, 'mse:', 1367.804953479837)\n",
      "('sweep no:', 283, 'mse:', 1367.8024913432291)\n",
      "('sweep no:', 284, 'mse:', 1367.8000629095486)\n",
      "('sweep no:', 285, 'mse:', 1367.7976677245765)\n",
      "('sweep no:', 286, 'mse:', 1367.7953053400715)\n",
      "('sweep no:', 287, 'mse:', 1367.7929753136032)\n",
      "('sweep no:', 288, 'mse:', 1367.7906772085344)\n",
      "('sweep no:', 289, 'mse:', 1367.7884105939547)\n",
      "('sweep no:', 290, 'mse:', 1367.786175044572)\n",
      "('sweep no:', 291, 'mse:', 1367.7839701406815)\n",
      "('sweep no:', 292, 'mse:', 1367.7817954680543)\n",
      "('sweep no:', 293, 'mse:', 1367.7796506179673)\n",
      "('sweep no:', 294, 'mse:', 1367.7775351869748)\n",
      "('sweep no:', 295, 'mse:', 1367.7754487770014)\n",
      "('sweep no:', 296, 'mse:', 1367.7733909951862)\n",
      "('sweep no:', 297, 'mse:', 1367.7713614538457)\n",
      "('sweep no:', 298, 'mse:', 1367.7693597703988)\n",
      "('sweep no:', 299, 'mse:', 1367.7673855673204)\n",
      "('sweep no:', 300, 'mse:', 1367.765438472053)\n",
      "('sweep no:', 301, 'mse:', 1367.763518116993)\n",
      "('sweep no:', 302, 'mse:', 1367.761624139344)\n",
      "('sweep no:', 303, 'mse:', 1367.7597561811556)\n",
      "('sweep no:', 304, 'mse:', 1367.7579138891924)\n",
      "('sweep no:', 305, 'mse:', 1367.7560969149044)\n",
      "('sweep no:', 306, 'mse:', 1367.7543049143653)\n",
      "('sweep no:', 307, 'mse:', 1367.7525375481935)\n",
      "('sweep no:', 308, 'mse:', 1367.7507944815468)\n",
      "('sweep no:', 309, 'mse:', 1367.7490753839838)\n",
      "('sweep no:', 310, 'mse:', 1367.7473799294921)\n",
      "('sweep no:', 311, 'mse:', 1367.7457077963818)\n",
      "('sweep no:', 312, 'mse:', 1367.7440586672546)\n",
      "('sweep no:', 313, 'mse:', 1367.742432228917)\n",
      "('sweep no:', 314, 'mse:', 1367.7408281723824)\n",
      "('sweep no:', 315, 'mse:', 1367.7392461927413)\n",
      "('sweep no:', 316, 'mse:', 1367.7376859891833)\n",
      "('sweep no:', 317, 'mse:', 1367.7361472649034)\n",
      "('sweep no:', 318, 'mse:', 1367.7346297270703)\n",
      "('sweep no:', 319, 'mse:', 1367.733133086741)\n",
      "('sweep no:', 320, 'mse:', 1367.7316570588673)\n",
      "('sweep no:', 321, 'mse:', 1367.730201362203)\n",
      "('sweep no:', 322, 'mse:', 1367.7287657192592)\n",
      "('sweep no:', 323, 'mse:', 1367.727349856262)\n",
      "('sweep no:', 324, 'mse:', 1367.7259535031312)\n",
      "('sweep no:', 325, 'mse:', 1367.724576393368)\n",
      "('sweep no:', 326, 'mse:', 1367.7232182640948)\n",
      "('sweep no:', 327, 'mse:', 1367.7218788559119)\n",
      "('sweep no:', 328, 'mse:', 1367.7205579129334)\n",
      "('sweep no:', 329, 'mse:', 1367.719255182727)\n",
      "('sweep no:', 330, 'mse:', 1367.717970416224)\n",
      "('sweep no:', 331, 'mse:', 1367.7167033677063)\n",
      "('sweep no:', 332, 'mse:', 1367.7154537947772)\n",
      "('sweep no:', 333, 'mse:', 1367.714221458287)\n",
      "('sweep no:', 334, 'mse:', 1367.7130061223374)\n",
      "('sweep no:', 335, 'mse:', 1367.7118075541669)\n",
      "('sweep no:', 336, 'mse:', 1367.7106255241802)\n",
      "('sweep no:', 337, 'mse:', 1367.7094598058493)\n",
      "('sweep no:', 338, 'mse:', 1367.7083101757412)\n",
      "('sweep no:', 339, 'mse:', 1367.7071764134196)\n",
      "('sweep no:', 340, 'mse:', 1367.7060583014177)\n",
      "('sweep no:', 341, 'mse:', 1367.7049556251968)\n",
      "('sweep no:', 342, 'mse:', 1367.7038681731558)\n",
      "('sweep no:', 343, 'mse:', 1367.7027957365326)\n",
      "('sweep no:', 344, 'mse:', 1367.7017381093694)\n",
      "('sweep no:', 345, 'mse:', 1367.700695088524)\n",
      "('sweep no:', 346, 'mse:', 1367.6996664735766)\n",
      "('sweep no:', 347, 'mse:', 1367.698652066867)\n",
      "('sweep no:', 348, 'mse:', 1367.697651673349)\n",
      "('sweep no:', 349, 'mse:', 1367.6966651006594)\n",
      "('sweep no:', 350, 'mse:', 1367.6956921590393)\n",
      "('sweep no:', 351, 'mse:', 1367.6947326613138)\n",
      "('sweep no:', 352, 'mse:', 1367.693786422813)\n",
      "('sweep no:', 353, 'mse:', 1367.6928532613856)\n",
      "('sweep no:', 354, 'mse:', 1367.6919329973632)\n",
      "('sweep no:', 355, 'mse:', 1367.691025453518)\n",
      "('sweep no:', 356, 'mse:', 1367.690130455023)\n",
      "('sweep no:', 357, 'mse:', 1367.689247829431)\n",
      "('sweep no:', 358, 'mse:', 1367.688377406628)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sweep no:', 359, 'mse:', 1367.687519018821)\n",
      "('sweep no:', 360, 'mse:', 1367.6866725004932)\n",
      "('sweep no:', 361, 'mse:', 1367.685837688384)\n",
      "('sweep no:', 362, 'mse:', 1367.6850144214563)\n",
      "('sweep no:', 363, 'mse:', 1367.6842025408744)\n",
      "('sweep no:', 364, 'mse:', 1367.6834018899349)\n",
      "('sweep no:', 365, 'mse:', 1367.6826123140834)\n",
      "('sweep no:', 366, 'mse:', 1367.6818336609113)\n",
      "('sweep no:', 367, 'mse:', 1367.6810657800256)\n",
      "('sweep no:', 368, 'mse:', 1367.6803085231063)\n",
      "('sweep no:', 369, 'mse:', 1367.6795617438736)\n",
      "('sweep no:', 370, 'mse:', 1367.6788252980243)\n",
      "('sweep no:', 371, 'mse:', 1367.6780990432053)\n",
      "('sweep no:', 372, 'mse:', 1367.677382839071)\n",
      "('sweep no:', 373, 'mse:', 1367.6766765471082)\n",
      "('sweep no:', 374, 'mse:', 1367.6759800307743)\n",
      "('sweep no:', 375, 'mse:', 1367.6752931553197)\n",
      "('sweep no:', 376, 'mse:', 1367.674615787888)\n",
      "('sweep no:', 377, 'mse:', 1367.6739477974195)\n",
      "('sweep no:', 378, 'mse:', 1367.6732890546452)\n",
      "('sweep no:', 379, 'mse:', 1367.6726394320513)\n",
      "('sweep no:', 380, 'mse:', 1367.671998803889)\n",
      "('sweep no:', 381, 'mse:', 1367.6713670461293)\n",
      "('sweep no:', 382, 'mse:', 1367.6707440364123)\n",
      "('sweep no:', 383, 'mse:', 1367.6701296540841)\n",
      "('sweep no:', 384, 'mse:', 1367.6695237801302)\n",
      "('sweep no:', 385, 'mse:', 1367.6689262971759)\n",
      "('sweep no:', 386, 'mse:', 1367.6683370894098)\n",
      "('sweep no:', 387, 'mse:', 1367.6677560426745)\n",
      "('sweep no:', 388, 'mse:', 1367.6671830443142)\n",
      "('sweep no:', 389, 'mse:', 1367.6666179832403)\n",
      "('sweep no:', 390, 'mse:', 1367.6660607499255)\n",
      "('sweep no:', 391, 'mse:', 1367.6655112362726)\n",
      "('sweep no:', 392, 'mse:', 1367.6649693357072)\n",
      "('sweep no:', 393, 'mse:', 1367.664434943126)\n",
      "('sweep no:', 394, 'mse:', 1367.6639079548322)\n",
      "('sweep no:', 395, 'mse:', 1367.6633882685871)\n",
      "('sweep no:', 396, 'mse:', 1367.6628757835342)\n",
      "('sweep no:', 397, 'mse:', 1367.6623704002068)\n",
      "('sweep no:', 398, 'mse:', 1367.6618720204883)\n",
      "('sweep no:', 399, 'mse:', 1367.6613805476422)\n",
      "('sweep no:', 400, 'mse:', 1367.6608958862228)\n",
      "('sweep no:', 401, 'mse:', 1367.660417942123)\n",
      "('sweep no:', 402, 'mse:', 1367.6599466225189)\n",
      "('sweep no:', 403, 'mse:', 1367.6594818358565)\n",
      "('sweep no:', 404, 'mse:', 1367.659023491842)\n",
      "('sweep no:', 405, 'mse:', 1367.6585715014285)\n",
      "('sweep no:', 406, 'mse:', 1367.6581257767832)\n",
      "('sweep no:', 407, 'mse:', 1367.657686231293)\n",
      "('sweep no:', 408, 'mse:', 1367.6572527795345)\n",
      "('sweep no:', 409, 'mse:', 1367.656825337231)\n",
      "('sweep no:', 410, 'mse:', 1367.6564038213025)\n",
      "('sweep no:', 411, 'mse:', 1367.6559881498026)\n",
      "('sweep no:', 412, 'mse:', 1367.6555782418873)\n",
      "('sweep no:', 413, 'mse:', 1367.6551740178468)\n",
      "('sweep no:', 414, 'mse:', 1367.654775399082)\n",
      "('sweep no:', 415, 'mse:', 1367.65438230804)\n",
      "('sweep no:', 416, 'mse:', 1367.6539946682728)\n",
      "('sweep no:', 417, 'mse:', 1367.6536124043325)\n",
      "('sweep no:', 418, 'mse:', 1367.6532354418641)\n",
      "('sweep no:', 419, 'mse:', 1367.6528637075194)\n",
      "('sweep no:', 420, 'mse:', 1367.6524971289552)\n",
      "('sweep no:', 421, 'mse:', 1367.652135634816)\n",
      "('sweep no:', 422, 'mse:', 1367.6517791547408)\n",
      "('sweep no:', 423, 'mse:', 1367.6514276193411)\n",
      "('sweep no:', 424, 'mse:', 1367.6510809601752)\n",
      "('sweep no:', 425, 'mse:', 1367.6507391097573)\n",
      "('sweep no:', 426, 'mse:', 1367.6504020015088)\n",
      "('sweep no:', 427, 'mse:', 1367.6500695697798)\n",
      "('sweep no:', 428, 'mse:', 1367.6497417498604)\n",
      "('sweep no:', 429, 'mse:', 1367.6494184778728)\n",
      "('sweep no:', 430, 'mse:', 1367.6490996908517)\n",
      "('sweep no:', 431, 'mse:', 1367.6487853267092)\n",
      "('sweep no:', 432, 'mse:', 1367.6484753241884)\n",
      "('sweep no:', 433, 'mse:', 1367.6481696228889)\n",
      "('sweep no:', 434, 'mse:', 1367.6478681632555)\n",
      "('sweep no:', 435, 'mse:', 1367.6475708865494)\n",
      "('sweep no:', 436, 'mse:', 1367.6472777348115)\n",
      "('sweep no:', 437, 'mse:', 1367.6469886509258)\n",
      "('sweep no:', 438, 'mse:', 1367.6467035785608)\n",
      "('sweep no:', 439, 'mse:', 1367.6464224621238)\n",
      "('sweep no:', 440, 'mse:', 1367.6461452468177)\n",
      "('sweep no:', 441, 'mse:', 1367.6458718786)\n",
      "('sweep no:', 442, 'mse:', 1367.6456023041953)\n",
      "('sweep no:', 443, 'mse:', 1367.6453364709926)\n",
      "('sweep no:', 444, 'mse:', 1367.6450743272019)\n",
      "('sweep no:', 445, 'mse:', 1367.644815821678)\n",
      "('sweep no:', 446, 'mse:', 1367.6445609040186)\n",
      "('sweep no:', 447, 'mse:', 1367.644309524496)\n",
      "('sweep no:', 448, 'mse:', 1367.6440616340758)\n",
      "('sweep no:', 449, 'mse:', 1367.643817184418)\n",
      "('sweep no:', 450, 'mse:', 1367.6435761278256)\n",
      "('sweep no:', 451, 'mse:', 1367.6433384172774)\n",
      "('sweep no:', 452, 'mse:', 1367.6431040063842)\n",
      "('sweep no:', 453, 'mse:', 1367.6428728494307)\n",
      "('sweep no:', 454, 'mse:', 1367.642644901302)\n",
      "('sweep no:', 455, 'mse:', 1367.6424201175091)\n",
      "('sweep no:', 456, 'mse:', 1367.642198454196)\n",
      "('sweep no:', 457, 'mse:', 1367.6419798680956)\n",
      "('sweep no:', 458, 'mse:', 1367.6417643165687)\n",
      "('sweep no:', 459, 'mse:', 1367.6415517575106)\n",
      "('sweep no:', 460, 'mse:', 1367.6413421494567)\n",
      "('sweep no:', 461, 'mse:', 1367.6411354514569)\n",
      "('sweep no:', 462, 'mse:', 1367.640931623212)\n",
      "('sweep no:', 463, 'mse:', 1367.6407306248939)\n",
      "('sweep no:', 464, 'mse:', 1367.6405324172738)\n",
      "('sweep no:', 465, 'mse:', 1367.6403369616505)\n",
      "('sweep no:', 466, 'mse:', 1367.6401442198382)\n",
      "('sweep no:', 467, 'mse:', 1367.6399541542403)\n",
      "('sweep no:', 468, 'mse:', 1367.6397667277295)\n",
      "('sweep no:', 469, 'mse:', 1367.6395819036707)\n",
      "('sweep no:', 470, 'mse:', 1367.63939964601)\n",
      "('sweep no:', 471, 'mse:', 1367.6392199191591)\n",
      "('sweep no:', 472, 'mse:', 1367.6390426879705)\n",
      "('sweep no:', 473, 'mse:', 1367.6388679178378)\n",
      "('sweep no:', 474, 'mse:', 1367.6386955746616)\n",
      "('sweep no:', 475, 'mse:', 1367.6385256247454)\n",
      "('sweep no:', 476, 'mse:', 1367.6383580348945)\n",
      "('sweep no:', 477, 'mse:', 1367.6381927723603)\n",
      "('sweep no:', 478, 'mse:', 1367.6380298048657)\n",
      "('sweep no:', 479, 'mse:', 1367.6378691005705)\n",
      "('sweep no:', 480, 'mse:', 1367.637710628084)\n",
      "('sweep no:', 481, 'mse:', 1367.6375543564259)\n",
      "('sweep no:', 482, 'mse:', 1367.6374002550772)\n",
      "('sweep no:', 483, 'mse:', 1367.6372482939116)\n",
      "('sweep no:', 484, 'mse:', 1367.6370984432328)\n",
      "('sweep no:', 485, 'mse:', 1367.636950673772)\n",
      "('sweep no:', 486, 'mse:', 1367.6368049566352)\n",
      "('sweep no:', 487, 'mse:', 1367.6366612633553)\n",
      "('sweep no:', 488, 'mse:', 1367.6365195658398)\n",
      "('sweep no:', 489, 'mse:', 1367.6363798363961)\n",
      "('sweep no:', 490, 'mse:', 1367.636242047711)\n",
      "('sweep no:', 491, 'mse:', 1367.636106172857)\n",
      "('sweep no:', 492, 'mse:', 1367.6359721852707)\n",
      "('sweep no:', 493, 'mse:', 1367.6358400587715)\n",
      "('sweep no:', 494, 'mse:', 1367.6357097674977)\n",
      "('sweep no:', 495, 'mse:', 1367.6355812860058)\n",
      "('sweep no:', 496, 'mse:', 1367.63545458918)\n",
      "('sweep no:', 497, 'mse:', 1367.635329652227)\n",
      "('sweep no:', 498, 'mse:', 1367.6352064507448)\n",
      "('sweep no:', 499, 'mse:', 1367.635084960631)\n",
      "('sweep no:', 500, 'mse:', 1367.634965158138)\n",
      "('sweep no:', 501, 'mse:', 1367.634847019836)\n",
      "('sweep no:', 502, 'mse:', 1367.6347305226195)\n",
      "('sweep no:', 503, 'mse:', 1367.6346156437107)\n",
      "('sweep no:', 504, 'mse:', 1367.6345023606577)\n",
      "('sweep no:', 505, 'mse:', 1367.6343906512848)\n",
      "('sweep no:', 506, 'mse:', 1367.6342804937751)\n",
      "('sweep no:', 507, 'mse:', 1367.6341718665617)\n",
      "('sweep no:', 508, 'mse:', 1367.6340647484005)\n",
      "('sweep no:', 509, 'mse:', 1367.633959118355)\n",
      "('sweep no:', 510, 'mse:', 1367.633854955753)\n",
      "('sweep no:', 511, 'mse:', 1367.6337522402298)\n",
      "('sweep no:', 512, 'mse:', 1367.6336509516898)\n",
      "('sweep no:', 513, 'mse:', 1367.6335510703152)\n",
      "('sweep no:', 514, 'mse:', 1367.6334525765926)\n",
      "('sweep no:', 515, 'mse:', 1367.6333554512244)\n",
      "('sweep no:', 516, 'mse:', 1367.6332596752293)\n",
      "('sweep no:', 517, 'mse:', 1367.6331652298759)\n",
      "('sweep no:', 518, 'mse:', 1367.633072096676)\n",
      "('sweep no:', 519, 'mse:', 1367.6329802574094)\n",
      "('sweep no:', 520, 'mse:', 1367.632889694116)\n",
      "('sweep no:', 521, 'mse:', 1367.6328003890796)\n",
      "('sweep no:', 522, 'mse:', 1367.6327123248104)\n",
      "('sweep no:', 523, 'mse:', 1367.6326254841126)\n",
      "('sweep no:', 524, 'mse:', 1367.6325398499546)\n",
      "('sweep no:', 525, 'mse:', 1367.63245540561)\n",
      "('sweep no:', 526, 'mse:', 1367.6323721345502)\n",
      "('sweep no:', 527, 'mse:', 1367.6322900204834)\n",
      "('sweep no:', 528, 'mse:', 1367.6322090473298)\n",
      "('sweep no:', 529, 'mse:', 1367.632129199267)\n",
      "('sweep no:', 530, 'mse:', 1367.6320504606495)\n",
      "('sweep no:', 531, 'mse:', 1367.631972816086)\n",
      "('sweep no:', 532, 'mse:', 1367.6318962503578)\n",
      "('sweep no:', 533, 'mse:', 1367.6318207485)\n",
      "('sweep no:', 534, 'mse:', 1367.6317462957456)\n",
      "('sweep no:', 535, 'mse:', 1367.6316728775091)\n",
      "('sweep no:', 536, 'mse:', 1367.6316004794235)\n",
      "('sweep no:', 537, 'mse:', 1367.6315290873194)\n",
      "('sweep no:', 538, 'mse:', 1367.6314586872347)\n",
      "('sweep no:', 539, 'mse:', 1367.6313892653952)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sweep no:', 540, 'mse:', 1367.6313208081738)\n",
      "('sweep no:', 541, 'mse:', 1367.6312533022185)\n",
      "('sweep no:', 542, 'mse:', 1367.6311867343022)\n",
      "('sweep no:', 543, 'mse:', 1367.6311210913882)\n",
      "('sweep no:', 544, 'mse:', 1367.6310563606412)\n",
      "('sweep no:', 545, 'mse:', 1367.6309925293735)\n",
      "('sweep no:', 546, 'mse:', 1367.630929585097)\n",
      "('sweep no:', 547, 'mse:', 1367.6308675154967)\n",
      "('sweep no:', 548, 'mse:', 1367.630806308428)\n",
      "('sweep no:', 549, 'mse:', 1367.6307459518928)\n",
      "('sweep no:', 550, 'mse:', 1367.6306864340904)\n",
      "('sweep no:', 551, 'mse:', 1367.63062774336)\n",
      "('sweep no:', 552, 'mse:', 1367.630569868223)\n",
      "('sweep no:', 553, 'mse:', 1367.6305127973417)\n",
      "('sweep no:', 554, 'mse:', 1367.6304565195514)\n",
      "('sweep no:', 555, 'mse:', 1367.6304010238164)\n",
      "('sweep no:', 556, 'mse:', 1367.6303462993023)\n",
      "('sweep no:', 557, 'mse:', 1367.6302923352625)\n",
      "('sweep no:', 558, 'mse:', 1367.6302391211475)\n",
      "('sweep no:', 559, 'mse:', 1367.6301866465533)\n",
      "('sweep no:', 560, 'mse:', 1367.6301349011837)\n",
      "('sweep no:', 561, 'mse:', 1367.6300838749173)\n",
      "('sweep no:', 562, 'mse:', 1367.630033557773)\n",
      "('sweep no:', 563, 'mse:', 1367.629983939887)\n",
      "('sweep no:', 564, 'mse:', 1367.629935011545)\n",
      "('sweep no:', 565, 'mse:', 1367.629886763169)\n",
      "('sweep no:', 566, 'mse:', 1367.6298391853138)\n",
      "('sweep no:', 567, 'mse:', 1367.6297922686583)\n",
      "('sweep no:', 568, 'mse:', 1367.6297460040291)\n",
      "('sweep no:', 569, 'mse:', 1367.6297003823588)\n",
      "('sweep no:', 570, 'mse:', 1367.629655394711)\n",
      "('sweep no:', 571, 'mse:', 1367.629611032274)\n",
      "('sweep no:', 572, 'mse:', 1367.6295672863805)\n",
      "('sweep no:', 573, 'mse:', 1367.629524148438)\n",
      "('sweep no:', 574, 'mse:', 1367.629481610029)\n",
      "('sweep no:', 575, 'mse:', 1367.629439662799)\n",
      "('sweep no:', 576, 'mse:', 1367.6293982985505)\n",
      "('sweep no:', 577, 'mse:', 1367.629357509165)\n",
      "('sweep no:', 578, 'mse:', 1367.6293172866708)\n",
      "('sweep no:', 579, 'mse:', 1367.6292776231878)\n",
      "('sweep no:', 580, 'mse:', 1367.6292385109437)\n",
      "('sweep no:', 581, 'mse:', 1367.6291999422847)\n",
      "('sweep no:', 582, 'mse:', 1367.6291619096578)\n",
      "('sweep no:', 583, 'mse:', 1367.6291244056233)\n",
      "('sweep no:', 584, 'mse:', 1367.629087422819)\n",
      "('sweep no:', 585, 'mse:', 1367.6290509539967)\n",
      "('sweep no:', 586, 'mse:', 1367.6290149920453)\n",
      "('sweep no:', 587, 'mse:', 1367.6289795299012)\n",
      "('sweep no:', 588, 'mse:', 1367.6289445606149)\n",
      "('sweep no:', 589, 'mse:', 1367.628910077353)\n",
      "('sweep no:', 590, 'mse:', 1367.628876073356)\n",
      "('sweep no:', 591, 'mse:', 1367.628842541953)\n",
      "('sweep no:', 592, 'mse:', 1367.6288094765855)\n",
      "('sweep no:', 593, 'mse:', 1367.6287768707905)\n",
      "('sweep no:', 594, 'mse:', 1367.6287447181694)\n",
      "('sweep no:', 595, 'mse:', 1367.6287130124197)\n",
      "('sweep no:', 596, 'mse:', 1367.628681747332)\n",
      "('sweep no:', 597, 'mse:', 1367.6286509168003)\n",
      "('sweep no:', 598, 'mse:', 1367.6286205147665)\n",
      "('sweep no:', 599, 'mse:', 1367.6285905352938)\n",
      "('sweep no:', 600, 'mse:', 1367.6285609724912)\n",
      "('sweep no:', 601, 'mse:', 1367.6285318205764)\n",
      "('sweep no:', 602, 'mse:', 1367.6285030738552)\n",
      "('sweep no:', 603, 'mse:', 1367.6284747266784)\n",
      "('sweep no:', 604, 'mse:', 1367.628446773486)\n",
      "('sweep no:', 605, 'mse:', 1367.6284192088287)\n",
      "('sweep no:', 606, 'mse:', 1367.628392027278)\n",
      "('sweep no:', 607, 'mse:', 1367.6283652235288)\n",
      "('sweep no:', 608, 'mse:', 1367.6283387923397)\n",
      "('sweep no:', 609, 'mse:', 1367.6283127285112)\n",
      "('sweep no:', 610, 'mse:', 1367.6282870269545)\n",
      "('sweep no:', 611, 'mse:', 1367.6282616826243)\n",
      "('sweep no:', 612, 'mse:', 1367.6282366905655)\n",
      "('sweep no:', 613, 'mse:', 1367.628212045871)\n",
      "('sweep no:', 614, 'mse:', 1367.6281877437154)\n",
      "('sweep no:', 615, 'mse:', 1367.628163779348)\n",
      "('sweep no:', 616, 'mse:', 1367.6281401480758)\n",
      "('sweep no:', 617, 'mse:', 1367.6281168452508)\n",
      "('sweep no:', 618, 'mse:', 1367.628093866321)\n",
      "('sweep no:', 619, 'mse:', 1367.6280712067999)\n",
      "('sweep no:', 620, 'mse:', 1367.6280488622212)\n",
      "('sweep no:', 621, 'mse:', 1367.6280268282214)\n",
      "('sweep no:', 622, 'mse:', 1367.6280051004933)\n",
      "('sweep no:', 623, 'mse:', 1367.6279836747688)\n",
      "('sweep no:', 624, 'mse:', 1367.6279625468355)\n",
      "('sweep no:', 625, 'mse:', 1367.6279417125943)\n",
      "('sweep no:', 626, 'mse:', 1367.6279211679255)\n",
      "('sweep no:', 627, 'mse:', 1367.627900908825)\n",
      "('sweep no:', 628, 'mse:', 1367.627880931322)\n",
      "('sweep no:', 629, 'mse:', 1367.6278612314984)\n",
      "('sweep no:', 630, 'mse:', 1367.6278418054883)\n",
      "('sweep no:', 631, 'mse:', 1367.627822649508)\n",
      "('sweep no:', 632, 'mse:', 1367.6278037597851)\n",
      "('sweep no:', 633, 'mse:', 1367.6277851326113)\n",
      "('sweep no:', 634, 'mse:', 1367.6277667643733)\n",
      "('sweep no:', 635, 'mse:', 1367.6277486514398)\n",
      "('sweep no:', 636, 'mse:', 1367.6277307902728)\n",
      "('sweep no:', 637, 'mse:', 1367.6277131773727)\n",
      "('sweep no:', 638, 'mse:', 1367.6276958092924)\n",
      "('sweep no:', 639, 'mse:', 1367.6276786826263)\n",
      "('sweep no:', 640, 'mse:', 1367.6276617940177)\n",
      "('sweep no:', 641, 'mse:', 1367.6276451401666)\n",
      "('sweep no:', 642, 'mse:', 1367.6276287177866)\n",
      "('sweep no:', 643, 'mse:', 1367.6276125236982)\n",
      "('sweep no:', 644, 'mse:', 1367.627596554699)\n",
      "('sweep no:', 645, 'mse:', 1367.627580807662)\n",
      "('sweep no:', 646, 'mse:', 1367.6275652795164)\n",
      "('sweep no:', 647, 'mse:', 1367.6275499672172)\n",
      "('sweep no:', 648, 'mse:', 1367.6275348677484)\n",
      "('sweep no:', 649, 'mse:', 1367.6275199781678)\n",
      "('sweep no:', 650, 'mse:', 1367.6275052955677)\n",
      "('sweep no:', 651, 'mse:', 1367.6274908170387)\n",
      "('sweep no:', 652, 'mse:', 1367.6274765397848)\n",
      "('sweep no:', 653, 'mse:', 1367.6274624609637)\n",
      "('sweep no:', 654, 'mse:', 1367.6274485778524)\n",
      "('sweep no:', 655, 'mse:', 1367.6274348877237)\n",
      "('sweep no:', 656, 'mse:', 1367.6274213878828)\n",
      "('sweep no:', 657, 'mse:', 1367.6274080756875)\n",
      "('sweep no:', 658, 'mse:', 1367.6273949485485)\n",
      "('sweep no:', 659, 'mse:', 1367.6273820038705)\n",
      "('sweep no:', 660, 'mse:', 1367.6273692391387)\n",
      "('sweep no:', 661, 'mse:', 1367.627356651826)\n",
      "('sweep no:', 662, 'mse:', 1367.6273442395002)\n",
      "('sweep no:', 663, 'mse:', 1367.627331999688)\n",
      "('sweep no:', 664, 'mse:', 1367.6273199300183)\n",
      "('sweep no:', 665, 'mse:', 1367.6273080281287)\n",
      "('sweep no:', 666, 'mse:', 1367.6272962916728)\n",
      "('sweep no:', 667, 'mse:', 1367.627284718362)\n",
      "('sweep no:', 668, 'mse:', 1367.6272733059131)\n",
      "('sweep no:', 669, 'mse:', 1367.6272620521233)\n",
      "('sweep no:', 670, 'mse:', 1367.6272509547568)\n",
      "('sweep no:', 671, 'mse:', 1367.6272400116536)\n",
      "('sweep no:', 672, 'mse:', 1367.627229220652)\n",
      "('sweep no:', 673, 'mse:', 1367.6272185796618)\n",
      "('sweep no:', 674, 'mse:', 1367.6272080865772)\n",
      "('sweep no:', 675, 'mse:', 1367.6271977393583)\n",
      "('sweep no:', 676, 'mse:', 1367.6271875359755)\n",
      "('sweep no:', 677, 'mse:', 1367.6271774744182)\n",
      "('sweep no:', 678, 'mse:', 1367.627167552715)\n",
      "('sweep no:', 679, 'mse:', 1367.627157768935)\n",
      "('sweep no:', 680, 'mse:', 1367.6271481211486)\n",
      "('sweep no:', 681, 'mse:', 1367.6271386074802)\n",
      "('sweep no:', 682, 'mse:', 1367.6271292260562)\n",
      "('sweep no:', 683, 'mse:', 1367.6271199750431)\n",
      "('sweep no:', 684, 'mse:', 1367.6271108526214)\n",
      "('sweep no:', 685, 'mse:', 1367.6271018570058)\n",
      "('sweep no:', 686, 'mse:', 1367.6270929864331)\n",
      "('sweep no:', 687, 'mse:', 1367.6270842391793)\n",
      "('sweep no:', 688, 'mse:', 1367.6270756135066)\n",
      "('sweep no:', 689, 'mse:', 1367.6270671077375)\n",
      "('sweep no:', 690, 'mse:', 1367.6270587202007)\n",
      "('sweep no:', 691, 'mse:', 1367.627050449251)\n",
      "('sweep no:', 692, 'mse:', 1367.62704229329)\n",
      "('sweep no:', 693, 'mse:', 1367.6270342506923)\n",
      "('sweep no:', 694, 'mse:', 1367.6270263199028)\n",
      "('sweep no:', 695, 'mse:', 1367.6270184993477)\n",
      "('sweep no:', 696, 'mse:', 1367.6270107875048)\n",
      "('sweep no:', 697, 'mse:', 1367.627003182857)\n",
      "('sweep no:', 698, 'mse:', 1367.6269956839124)\n",
      "('sweep no:', 699, 'mse:', 1367.6269882892284)\n",
      "('sweep no:', 700, 'mse:', 1367.6269809973312)\n",
      "('sweep no:', 701, 'mse:', 1367.626973806791)\n",
      "('sweep no:', 702, 'mse:', 1367.6269667162073)\n",
      "('sweep no:', 703, 'mse:', 1367.626959724197)\n",
      "('sweep no:', 704, 'mse:', 1367.6269528293642)\n",
      "('sweep no:', 705, 'mse:', 1367.6269460303859)\n",
      "('sweep no:', 706, 'mse:', 1367.6269393259165)\n",
      "('sweep no:', 707, 'mse:', 1367.6269327146458)\n",
      "('sweep no:', 708, 'mse:', 1367.6269261952716)\n",
      "('sweep no:', 709, 'mse:', 1367.6269197665363)\n",
      "('sweep no:', 710, 'mse:', 1367.626913427155)\n",
      "('sweep no:', 711, 'mse:', 1367.6269071759016)\n",
      "('sweep no:', 712, 'mse:', 1367.626901011542)\n",
      "('sweep no:', 713, 'mse:', 1367.626894932863)\n",
      "('sweep no:', 714, 'mse:', 1367.6268889387022)\n",
      "('sweep no:', 715, 'mse:', 1367.6268830278518)\n",
      "('sweep no:', 716, 'mse:', 1367.6268771991763)\n",
      "('sweep no:', 717, 'mse:', 1367.6268714515077)\n",
      "('sweep no:', 718, 'mse:', 1367.6268657837545)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sweep no:', 719, 'mse:', 1367.6268601947866)\n",
      "('sweep no:', 720, 'mse:', 1367.6268546835108)\n",
      "('sweep no:', 721, 'mse:', 1367.626849248835)\n",
      "('sweep no:', 722, 'mse:', 1367.6268438897148)\n",
      "('sweep no:', 723, 'mse:', 1367.626838605087)\n",
      "('sweep no:', 724, 'mse:', 1367.6268333939338)\n",
      "('sweep no:', 725, 'mse:', 1367.6268282551982)\n",
      "('sweep no:', 726, 'mse:', 1367.626823187913)\n",
      "('sweep no:', 727, 'mse:', 1367.6268181910636)\n",
      "('sweep no:', 728, 'mse:', 1367.6268132636787)\n",
      "('sweep no:', 729, 'mse:', 1367.6268084047827)\n",
      "('sweep no:', 730, 'mse:', 1367.6268036134338)\n",
      "('sweep no:', 731, 'mse:', 1367.6267988886927)\n",
      "('sweep no:', 732, 'mse:', 1367.6267942296154)\n",
      "('sweep no:', 733, 'mse:', 1367.6267896353233)\n",
      "('sweep no:', 734, 'mse:', 1367.62678510488)\n",
      "('sweep no:', 735, 'mse:', 1367.6267806374221)\n",
      "('sweep no:', 736, 'mse:', 1367.6267762320645)\n",
      "('sweep no:', 737, 'mse:', 1367.6267718879512)\n",
      "('sweep no:', 738, 'mse:', 1367.6267676042178)\n",
      "('sweep no:', 739, 'mse:', 1367.626763380034)\n",
      "('sweep no:', 740, 'mse:', 1367.6267592145764)\n",
      "('sweep no:', 741, 'mse:', 1367.6267551070225)\n",
      "('sweep no:', 742, 'mse:', 1367.6267510565597)\n",
      "('sweep no:', 743, 'mse:', 1367.6267470624055)\n",
      "('sweep no:', 744, 'mse:', 1367.6267431237718)\n",
      "('sweep no:', 745, 'mse:', 1367.626739239906)\n",
      "('sweep no:', 746, 'mse:', 1367.6267354100182)\n",
      "('sweep no:', 747, 'mse:', 1367.6267316333629)\n",
      "('sweep no:', 748, 'mse:', 1367.626727909214)\n",
      "('sweep no:', 749, 'mse:', 1367.6267242368397)\n",
      "('sweep no:', 750, 'mse:', 1367.6267206155076)\n",
      "('sweep no:', 751, 'mse:', 1367.6267170445235)\n",
      "('sweep no:', 752, 'mse:', 1367.6267135231656)\n",
      "('sweep no:', 753, 'mse:', 1367.6267100507675)\n",
      "('sweep no:', 754, 'mse:', 1367.6267066266362)\n",
      "('sweep no:', 755, 'mse:', 1367.6267032501235)\n",
      "('sweep no:', 756, 'mse:', 1367.6266999205295)\n",
      "('sweep no:', 757, 'mse:', 1367.6266966372166)\n",
      "('sweep no:', 758, 'mse:', 1367.626693399547)\n",
      "('sweep no:', 759, 'mse:', 1367.6266902068944)\n",
      "('sweep no:', 760, 'mse:', 1367.62668705862)\n",
      "('sweep no:', 761, 'mse:', 1367.626683954115)\n",
      "('sweep no:', 762, 'mse:', 1367.6266808927567)\n",
      "('sweep no:', 763, 'mse:', 1367.6266778739525)\n",
      "('sweep no:', 764, 'mse:', 1367.6266748971223)\n",
      "('sweep no:', 765, 'mse:', 1367.6266719616708)\n",
      "('sweep no:', 766, 'mse:', 1367.6266690670245)\n",
      "('sweep no:', 767, 'mse:', 1367.626666212612)\n",
      "('sweep no:', 768, 'mse:', 1367.6266633978842)\n",
      "('sweep no:', 769, 'mse:', 1367.6266606222864)\n",
      "('sweep no:', 770, 'mse:', 1367.6266578852692)\n",
      "('sweep no:', 771, 'mse:', 1367.6266551863046)\n",
      "('sweep no:', 772, 'mse:', 1367.626652524858)\n",
      "('sweep no:', 773, 'mse:', 1367.6266499004007)\n",
      "('sweep no:', 774, 'mse:', 1367.6266473124372)\n",
      "('sweep no:', 775, 'mse:', 1367.626644760432)\n",
      "('sweep no:', 776, 'mse:', 1367.626642243913)\n",
      "('sweep no:', 777, 'mse:', 1367.626639762378)\n",
      "('sweep no:', 778, 'mse:', 1367.6266373153435)\n",
      "('sweep no:', 779, 'mse:', 1367.6266349023267)\n",
      "('sweep no:', 780, 'mse:', 1367.6266325228437)\n",
      "('sweep no:', 781, 'mse:', 1367.6266301764367)\n",
      "('sweep no:', 782, 'mse:', 1367.626627862653)\n",
      "('sweep no:', 783, 'mse:', 1367.626625581037)\n",
      "('sweep no:', 784, 'mse:', 1367.626623331137)\n",
      "('sweep no:', 785, 'mse:', 1367.6266211125064)\n",
      "('sweep no:', 786, 'mse:', 1367.626618924728)\n",
      "('sweep no:', 787, 'mse:', 1367.6266167673612)\n",
      "('sweep no:', 788, 'mse:', 1367.6266146399823)\n",
      "('sweep no:', 789, 'mse:', 1367.6266125421735)\n",
      "('sweep no:', 790, 'mse:', 1367.6266104735255)\n",
      "('sweep no:', 791, 'mse:', 1367.6266084336414)\n",
      "('sweep no:', 792, 'mse:', 1367.6266064221077)\n",
      "('sweep no:', 793, 'mse:', 1367.6266044385327)\n",
      "('sweep no:', 794, 'mse:', 1367.6266024825388)\n",
      "('sweep no:', 795, 'mse:', 1367.6266005537314)\n",
      "('sweep no:', 796, 'mse:', 1367.6265986517374)\n",
      "('sweep no:', 797, 'mse:', 1367.6265967761883)\n",
      "('sweep no:', 798, 'mse:', 1367.6265949267024)\n",
      "('sweep no:', 799, 'mse:', 1367.6265931029338)\n",
      "('sweep no:', 800, 'mse:', 1367.6265913045247)\n",
      "('sweep no:', 801, 'mse:', 1367.626589531105)\n",
      "('sweep no:', 802, 'mse:', 1367.6265877823464)\n",
      "('sweep no:', 803, 'mse:', 1367.6265860578856)\n",
      "('sweep no:', 804, 'mse:', 1367.6265843574092)\n",
      "('sweep no:', 805, 'mse:', 1367.626582680563)\n",
      "('sweep no:', 806, 'mse:', 1367.6265810270236)\n",
      "('sweep no:', 807, 'mse:', 1367.6265793964812)\n",
      "('sweep no:', 808, 'mse:', 1367.626577788604)\n",
      "('sweep no:', 809, 'mse:', 1367.6265762030725)\n",
      "('sweep no:', 810, 'mse:', 1367.6265746395914)\n",
      "('sweep no:', 811, 'mse:', 1367.6265730978396)\n",
      "('sweep no:', 812, 'mse:', 1367.6265715775166)\n",
      "('sweep no:', 813, 'mse:', 1367.6265700783317)\n",
      "('sweep no:', 814, 'mse:', 1367.6265685999838)\n",
      "('sweep no:', 815, 'mse:', 1367.6265671421872)\n",
      "('sweep no:', 816, 'mse:', 1367.6265657046565)\n",
      "('sweep no:', 817, 'mse:', 1367.6265642871072)\n",
      "('sweep no:', 818, 'mse:', 1367.6265628892631)\n",
      "('sweep no:', 819, 'mse:', 1367.62656151086)\n",
      "('sweep no:', 820, 'mse:', 1367.6265601516084)\n",
      "('sweep no:', 821, 'mse:', 1367.6265588112624)\n",
      "('sweep no:', 822, 'mse:', 1367.626557489537)\n",
      "('sweep no:', 823, 'mse:', 1367.6265561861894)\n",
      "('sweep no:', 824, 'mse:', 1367.6265549009706)\n",
      "('sweep no:', 825, 'mse:', 1367.6265536336052)\n",
      "('sweep no:', 826, 'mse:', 1367.62655238386)\n",
      "('sweep no:', 827, 'mse:', 1367.626551151488)\n",
      "('sweep no:', 828, 'mse:', 1367.6265499362587)\n",
      "('sweep no:', 829, 'mse:', 1367.6265487379046)\n",
      "('sweep no:', 830, 'mse:', 1367.6265475562182)\n",
      "('sweep no:', 831, 'mse:', 1367.6265463909583)\n",
      "('sweep no:', 832, 'mse:', 1367.6265452419027)\n",
      "('sweep no:', 833, 'mse:', 1367.6265441088142)\n",
      "('sweep no:', 834, 'mse:', 1367.626542991474)\n",
      "('sweep no:', 835, 'mse:', 1367.626541889669)\n",
      "('sweep no:', 836, 'mse:', 1367.6265408031875)\n",
      "('sweep no:', 837, 'mse:', 1367.6265397318002)\n",
      "('sweep no:', 838, 'mse:', 1367.6265386753073)\n",
      "('sweep no:', 839, 'mse:', 1367.6265376334943)\n",
      "('sweep no:', 840, 'mse:', 1367.626536606177)\n",
      "('sweep no:', 841, 'mse:', 1367.6265355931425)\n",
      "('sweep no:', 842, 'mse:', 1367.6265345941881)\n",
      "('sweep no:', 843, 'mse:', 1367.6265336091146)\n",
      "('sweep no:', 844, 'mse:', 1367.6265326377377)\n",
      "('sweep no:', 845, 'mse:', 1367.6265316798658)\n",
      "('sweep no:', 846, 'mse:', 1367.6265307353024)\n",
      "('sweep no:', 847, 'mse:', 1367.626529803883)\n",
      "('sweep no:', 848, 'mse:', 1367.6265288853995)\n",
      "('sweep no:', 849, 'mse:', 1367.6265279796885)\n",
      "('sweep no:', 850, 'mse:', 1367.6265270865767)\n",
      "('sweep no:', 851, 'mse:', 1367.6265262058648)\n",
      "('sweep no:', 852, 'mse:', 1367.6265253374017)\n",
      "('sweep no:', 853, 'mse:', 1367.6265244810115)\n",
      "('sweep no:', 854, 'mse:', 1367.626523636522)\n",
      "('sweep no:', 855, 'mse:', 1367.6265228037785)\n",
      "('sweep no:', 856, 'mse:', 1367.6265219826116)\n",
      "('sweep no:', 857, 'mse:', 1367.6265211728596)\n",
      "('sweep no:', 858, 'mse:', 1367.6265203743642)\n",
      "('sweep no:', 859, 'mse:', 1367.626519586964)\n",
      "('sweep no:', 860, 'mse:', 1367.6265188105147)\n",
      "('sweep no:', 861, 'mse:', 1367.626518044864)\n",
      "('sweep no:', 862, 'mse:', 1367.626517289854)\n",
      "('sweep no:', 863, 'mse:', 1367.6265165453221)\n",
      "('sweep no:', 864, 'mse:', 1367.626515811162)\n",
      "('sweep no:', 865, 'mse:', 1367.6265150871957)\n",
      "('sweep no:', 866, 'mse:', 1367.626514373299)\n",
      "('sweep no:', 867, 'mse:', 1367.626513669323)\n",
      "('sweep no:', 868, 'mse:', 1367.6265129751393)\n",
      "('sweep no:', 869, 'mse:', 1367.6265122905959)\n",
      "('sweep no:', 870, 'mse:', 1367.6265116155835)\n",
      "('sweep no:', 871, 'mse:', 1367.6265109499361)\n",
      "('sweep no:', 872, 'mse:', 1367.6265102935506)\n",
      "('sweep no:', 873, 'mse:', 1367.6265096462914)\n",
      "('sweep no:', 874, 'mse:', 1367.6265090080292)\n",
      "('sweep no:', 875, 'mse:', 1367.62650837864)\n",
      "('sweep no:', 876, 'mse:', 1367.6265077579988)\n",
      "('sweep no:', 877, 'mse:', 1367.6265071459882)\n",
      "('sweep no:', 878, 'mse:', 1367.6265065424918)\n",
      "('sweep no:', 879, 'mse:', 1367.6265059473712)\n",
      "('sweep no:', 880, 'mse:', 1367.626505360527)\n",
      "('sweep no:', 881, 'mse:', 1367.6265047818445)\n",
      "('sweep no:', 882, 'mse:', 1367.6265042112052)\n",
      "('sweep no:', 883, 'mse:', 1367.6265036484897)\n",
      "('sweep no:', 884, 'mse:', 1367.6265030936133)\n",
      "('sweep no:', 885, 'mse:', 1367.6265025464381)\n",
      "('sweep no:', 886, 'mse:', 1367.6265020068765)\n",
      "('sweep no:', 887, 'mse:', 1367.626501474813)\n",
      "('sweep no:', 888, 'mse:', 1367.6265009501396)\n",
      "('sweep no:', 889, 'mse:', 1367.6265004327608)\n",
      "('sweep no:', 890, 'mse:', 1367.6264999225925)\n",
      "('sweep no:', 891, 'mse:', 1367.6264994195005)\n",
      "('sweep no:', 892, 'mse:', 1367.626498923404)\n",
      "('sweep no:', 893, 'mse:', 1367.626498434204)\n",
      "('sweep no:', 894, 'mse:', 1367.626497951808)\n",
      "('sweep no:', 895, 'mse:', 1367.6264974761057)\n",
      "('sweep no:', 896, 'mse:', 1367.6264970070242)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sweep no:', 897, 'mse:', 1367.626496544478)\n",
      "('sweep no:', 898, 'mse:', 1367.6264960883439)\n",
      "('sweep no:', 899, 'mse:', 1367.6264956385578)\n",
      "('sweep no:', 900, 'mse:', 1367.6264951950113)\n",
      "('sweep no:', 901, 'mse:', 1367.6264947576467)\n",
      "('sweep no:', 902, 'mse:', 1367.6264943263525)\n",
      "('sweep no:', 903, 'mse:', 1367.6264939010694)\n",
      "('sweep no:', 904, 'mse:', 1367.6264934816788)\n",
      "('sweep no:', 905, 'mse:', 1367.626493068115)\n",
      "('sweep no:', 906, 'mse:', 1367.6264926603217)\n",
      "('sweep no:', 907, 'mse:', 1367.6264922581875)\n",
      "('sweep no:', 908, 'mse:', 1367.6264918616382)\n",
      "('sweep no:', 909, 'mse:', 1367.6264914706117)\n",
      "('sweep no:', 910, 'mse:', 1367.6264910850184)\n",
      "('sweep no:', 911, 'mse:', 1367.626490704777)\n",
      "('sweep no:', 912, 'mse:', 1367.626490329831)\n",
      "('sweep no:', 913, 'mse:', 1367.6264899600963)\n",
      "('sweep no:', 914, 'mse:', 1367.6264895954962)\n",
      "('sweep no:', 915, 'mse:', 1367.6264892359668)\n",
      "('sweep no:', 916, 'mse:', 1367.6264888814358)\n",
      "('sweep no:', 917, 'mse:', 1367.6264885318355)\n",
      "('sweep no:', 918, 'mse:', 1367.6264881870911)\n",
      "('sweep no:', 919, 'mse:', 1367.6264878471347)\n",
      "('sweep no:', 920, 'mse:', 1367.6264875119173)\n",
      "('sweep no:', 921, 'mse:', 1367.6264871813457)\n",
      "('sweep no:', 922, 'mse:', 1367.6264868553833)\n",
      "('sweep no:', 923, 'mse:', 1367.626486533942)\n",
      "('sweep no:', 924, 'mse:', 1367.626486216968)\n",
      "('sweep no:', 925, 'mse:', 1367.626485904409)\n",
      "('sweep no:', 926, 'mse:', 1367.6264855961886)\n",
      "('sweep no:', 927, 'mse:', 1367.6264852922568)\n",
      "('sweep no:', 928, 'mse:', 1367.6264849925562)\n",
      "('sweep no:', 929, 'mse:', 1367.6264846970105)\n",
      "('sweep no:', 930, 'mse:', 1367.6264844055818)\n",
      "('sweep no:', 931, 'mse:', 1367.626484118196)\n",
      "('sweep no:', 932, 'mse:', 1367.626483834804)\n",
      "('sweep no:', 933, 'mse:', 1367.6264835553584)\n",
      "('sweep no:', 934, 'mse:', 1367.626483279791)\n",
      "('sweep no:', 935, 'mse:', 1367.62648300807)\n",
      "('sweep no:', 936, 'mse:', 1367.6264827401023)\n",
      "('sweep no:', 937, 'mse:', 1367.6264824758773)\n",
      "('sweep no:', 938, 'mse:', 1367.626482215317)\n",
      "('sweep no:', 939, 'mse:', 1367.6264819583914)\n",
      "('sweep no:', 940, 'mse:', 1367.6264817050278)\n",
      "('sweep no:', 941, 'mse:', 1367.626481455173)\n",
      "('sweep no:', 942, 'mse:', 1367.626481208816)\n",
      "('sweep no:', 943, 'mse:', 1367.6264809658705)\n",
      "('sweep no:', 944, 'mse:', 1367.6264807263062)\n",
      "('sweep no:', 945, 'mse:', 1367.6264804900675)\n",
      "('sweep no:', 946, 'mse:', 1367.6264802571163)\n",
      "('sweep no:', 947, 'mse:', 1367.6264800274048)\n",
      "('sweep no:', 948, 'mse:', 1367.626479800887)\n",
      "('sweep no:', 949, 'mse:', 1367.6264795775232)\n",
      "('sweep no:', 950, 'mse:', 1367.6264793572498)\n",
      "('sweep no:', 951, 'mse:', 1367.6264791400463)\n",
      "('sweep no:', 952, 'mse:', 1367.6264789258573)\n",
      "('sweep no:', 953, 'mse:', 1367.6264787146515)\n",
      "('sweep no:', 954, 'mse:', 1367.6264785063777)\n",
      "('sweep no:', 955, 'mse:', 1367.6264783010095)\n",
      "('sweep no:', 956, 'mse:', 1367.6264780984857)\n",
      "('sweep no:', 957, 'mse:', 1367.6264778987825)\n",
      "('sweep no:', 958, 'mse:', 1367.6264777018528)\n",
      "('sweep no:', 959, 'mse:', 1367.6264775076659)\n",
      "('sweep no:', 960, 'mse:', 1367.6264773161688)\n",
      "('sweep no:', 961, 'mse:', 1367.6264771273454)\n",
      "('sweep no:', 962, 'mse:', 1367.6264769411334)\n",
      "('sweep no:', 963, 'mse:', 1367.626476757529)\n",
      "('sweep no:', 964, 'mse:', 1367.6264765764606)\n",
      "('sweep no:', 965, 'mse:', 1367.6264763979066)\n",
      "('sweep no:', 966, 'mse:', 1367.626476221848)\n",
      "('sweep no:', 967, 'mse:', 1367.626476048225)\n",
      "('sweep no:', 968, 'mse:', 1367.626475877026)\n",
      "('sweep no:', 969, 'mse:', 1367.6264757081951)\n",
      "('sweep no:', 970, 'mse:', 1367.6264755417133)\n",
      "('sweep no:', 971, 'mse:', 1367.6264753775604)\n",
      "('sweep no:', 972, 'mse:', 1367.626475215681)\n",
      "('sweep no:', 973, 'mse:', 1367.6264750560538)\n",
      "('sweep no:', 974, 'mse:', 1367.6264748986437)\n",
      "('sweep no:', 975, 'mse:', 1367.6264747434163)\n",
      "('sweep no:', 976, 'mse:', 1367.626474590345)\n",
      "('sweep no:', 977, 'mse:', 1367.6264744394034)\n",
      "('sweep no:', 978, 'mse:', 1367.6264742905812)\n",
      "('sweep no:', 979, 'mse:', 1367.626474143807)\n",
      "('sweep no:', 980, 'mse:', 1367.6264739990752)\n",
      "('sweep no:', 981, 'mse:', 1367.6264738563605)\n",
      "('sweep no:', 982, 'mse:', 1367.6264737156232)\n",
      "('sweep no:', 983, 'mse:', 1367.6264735768555)\n",
      "('sweep no:', 984, 'mse:', 1367.6264734399988)\n",
      "('sweep no:', 985, 'mse:', 1367.6264733050489)\n",
      "('sweep no:', 986, 'mse:', 1367.6264731719823)\n",
      "('sweep no:', 987, 'mse:', 1367.626473040765)\n",
      "('sweep no:', 988, 'mse:', 1367.6264729113627)\n",
      "('sweep no:', 989, 'mse:', 1367.626472783767)\n",
      "('sweep no:', 990, 'mse:', 1367.6264726579584)\n",
      "('sweep no:', 991, 'mse:', 1367.6264725338635)\n",
      "('sweep no:', 992, 'mse:', 1367.626472411523)\n",
      "('sweep no:', 993, 'mse:', 1367.6264722908816)\n",
      "('sweep no:', 994, 'mse:', 1367.6264721719072)\n",
      "('sweep no:', 995, 'mse:', 1367.6264720545873)\n",
      "('sweep no:', 996, 'mse:', 1367.6264719388998)\n",
      "('sweep no:', 997, 'mse:', 1367.6264718248206)\n",
      "('sweep no:', 998, 'mse:', 1367.6264717123368)\n",
      "('sweep no:', 999, 'mse:', 1367.6264716013989)\n"
     ]
    }
   ],
   "source": [
    "for i in range(sweep):\n",
    "    for users in range(num_users):\n",
    "        X = user_updt(users, X, Y)\n",
    "        \n",
    "    for items in range(num_items):\n",
    "        Y = item_updt(items, X, Y)\n",
    "    \n",
    "    \n",
    "    confidence_gathered = confidence_matrix.reshape(-1, 1)\n",
    "    \n",
    "    conf = ((_alpha * confidence_gathered) +\n",
    "                  np.reshape(np.ones(shape=[np.shape(confidence_gathered)[0]]), [-1, 1]))\n",
    "        \n",
    "    regularizer_Y  =  np.linalg.norm(Y)\n",
    "    regularizer_X  =  np.linalg.norm(X) \n",
    "    \n",
    "    sq_diff = np.square(true_matrix - np.matmul(X, np.transpose(Y)))\n",
    "    \n",
    "    mse = np.sum(np.sum(np.reshape(conf, [num_users, -1]) * sq_diff)) + _beta * (regularizer_X + regularizer_Y)\n",
    "    print('sweep no:', i, 'mse:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Class </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class tf_network_init:\n",
    "    \n",
    "    tf = __import__('tensorflow')\n",
    "    csv = __import__('csv')\n",
    "    time = __import__('time')\n",
    "    os = __import__('os')\n",
    "\n",
    "    # parameters\n",
    "    rank = [50, 100, 150, 200, 250, 300, 350]\n",
    "    lr_rat = 0.0001\n",
    "    num_users = int(true_matrix.shape[0])\n",
    "    num_items = int(true_matrix.shape[1])\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tf.reset_default_graph()\n",
    "        \n",
    "    def init_vars(self):    \n",
    "        self.Y = {'low_m': tf.Variable(tf.random_normal([n_users, _rank], mean=0.0,\n",
    "        stddev=0.1) , name  =  'low_p', validate_shape = False),\n",
    "                'low_b': tf.Variable(tf.random_normal([n_users, 1], mean=0.0,\n",
    "        stddev=0.1), name = 'low_p_b')}\n",
    "\n",
    "        self.B = {'basis_m': tf.Variable(tf.random_normal([_rank, n_items], mean=0.0,\n",
    "        stddev=0.1), name = 'base', validate_shape = False),\n",
    "                'basis_b': tf.Variable(tf.random_normal([1, n_items], mean=0.0,\n",
    "        stddev=0.1), name = 'base_b')}\n",
    "        return(self.Y, self.B)\n",
    "        \n",
    "    def writ_meth_to_csv(self, full_path):\n",
    "        if(os.path.isfile(full_path  + '_.csv')): \n",
    "            self.writing_method = 'a'\n",
    "        else:\n",
    "            self.writing_method = 'wb'\n",
    "        return (self.writing_method)\n",
    "    \n",
    "    def init_plh(self):\n",
    "        self._idx = tf.placeholder(\"int32\", [None, 2], name  =  'utility_matrix_idx')\n",
    "        self._beta = tf.placeholder(\"float32\", [], name = 'regularization')\n",
    "        self._num = tf.placeholder(\"float32\", [])\n",
    "        return(self._idx, self._beta, self._num)\n",
    "    \n",
    "    def tb_summary_init(self, path, weights, loss_param ,accuracy_param):\n",
    "        self.logs_path_1  =  os.path.join('./' + path, 'run_%d' % run, 'plot_1')\n",
    "        self.logs_path_2  =  os.path.join('./' + path, 'run_%d' % run, 'plot_2')\n",
    "        tf.summary.histogram(\"weights_y\", Y['low_m'])\n",
    "        tf.summary.histogram(\"weights_b\", B['basis_m'])        \n",
    "        self.tf.summary.scalar(\"loss\" , loss_param)\n",
    "        self.tf.summary.scalar(\"accuracy\",  accuracy_param)\n",
    "        self.summary_op = tf.summary.merge_all()\n",
    "        self.writer_1 = tf.summary.FileWriter(self.logs_path_1, graph = tf.get_default_graph())\n",
    "        self.writer_2 = tf.summary.FileWriter(self.logs_path_2, graph = tf.get_default_graph())\n",
    "        return(self.summary_op, self.writer_1, self.writer_2)\n",
    "    \n",
    "    def init_network(self, full_path, path, loss_param ,accuracy_param):\n",
    "        self.summary_op, self.writer_1,self.writer_2 = tb_summary_init(self, path, weights, loss_param, accuracy_param)\n",
    "        self.saver = tf.train.Saver(write_version = tf.train.SaverDef.V2)\n",
    "        self.sess = graph_init()\n",
    "        self.writing_method = writ_meth_to_csv(full_path)\n",
    "        return(self.saver, self.summary_op, self.writer_1, self.writer_2, self.writing_method, self.sess)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # training parameters\n",
    "    beta_power = np.asarray(list(drange(-4, 4.25, 0.25)))\n",
    "    beta = (10 ** beta_power).astype('float32')\n",
    "    n_iter = 100000\n",
    "    k = 5 \n",
    "    restored = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_network(full_path, path):\n",
    "    with open(full_path + '_.csv', writing_method) as csvfile:\n",
    "        wr  =  csv.writer(csvfile,  delimiter = '\\t',  lineterminator = '\\n')\n",
    "        wr.writerow(['Run', 'Iteration', \"loss\", \"accuracy\", \"time\", \"beta\", \"factors\" ,\"lr_rat\", \"train/valid\", 'restored'])\n",
    "\n",
    "        for bet in beta:\n",
    "            print ('training for beta = %.4f'% bet)\n",
    "            t0 = time.time()\n",
    "            for iteration in range(int(n_iter)):\n",
    "                for c_val_num in range(1, k + 1):\n",
    "                    tr_idx, _num_t ,val_idx, _num_v = cross_val_miss_mat(k, c_val_num, m)\n",
    "\n",
    "                    if ((iteration + 1) % 1000 == 0):\n",
    "                        _loss_val, _accu_val, summary = sess.run([loss, accuracy, summary_op]\n",
    "                      , feed_dict = { _idx : val_idx,\n",
    "                                     _beta: bet,\n",
    "                                     _num: _num_v,\n",
    "                                    })\n",
    "                        writer_2.add_summary(summary, iteration)\n",
    "\n",
    "\n",
    "\n",
    "                        wr.writerow([run, iteration, _loss_val, _accu_val, str(datetime.datetime.now()), beta, _rank, \n",
    "                             lr_rat, c_val_num, \"valid\", restored])\n",
    "\n",
    "                    _loss_tr, _accu_tr,  _, summary = sess.run([loss, accuracy, opt, summary_op]\n",
    "                  , feed_dict = { _idx : tr_idx, _beta: bet,  _num: _num_t})\n",
    "\n",
    "                    if ((iteration + 1) % 1000 == 0):\n",
    "                        t1 = time.time()\n",
    "                        print('cv:', c_val_num,'Iteration', iteration, 'train mse:', _loss_tr,\n",
    "                                 'train rmse:', _acc_tr)\n",
    "                        print('cv:', c_val_num, 'Iteration', iteration, 'validation mse:', _loss_val,\n",
    "                             'validation rmse:', _acc_val)\n",
    "                        print(iteration,'iterations took:',  t1 - t0, 'seconds')\n",
    "\n",
    "                        writer_1.add_summary(summary, iteration)\n",
    "\n",
    "                        wr.writerow([run, iteration, _loss_tr, _accu_tr, str(datetime.datetime.now()), beta,\n",
    "                             _rank, lr_rat, c_val_num, \"train\", restored])\n",
    "\n",
    "                    if ((iteration + 1) % 5000 == 0):\n",
    "                        folder  =  os.path.join('./' + path, 'run_%d' % run, 'iter_%d' % iteration, 'weights')\n",
    "                        save_path  =  saver.save(sess,  folder + '_')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main_network(Y, B, _beta, _alpha, true_matrix, confidence_matrix, _num, _idx):\n",
    "    \n",
    "    app_x = tf.matmul((Y['low_m'] + Y['low_b']), \n",
    "                         B['basis_m'] + B['basis_b'])\n",
    "        \n",
    "    _true  =  tf.reshape(tf.gather_nd(params  =  true_matrix,\n",
    "                                indices  = _idx), [-1, 1])\n",
    "\n",
    "    _pred = tf.reshape(tf.gather_nd(app_x, indices = _idx), [-1, 1])\n",
    "    \n",
    "    confidence_gathered = tf.reshape(tf.gather_nd(confidence_matrix, indices = _idx), [-1, 1])\n",
    "    \n",
    "    \n",
    "    num_u = tf.shape(true_matrix)[0]\n",
    "    num_i = tf.shape(tf.reshape(_pred, [num_u, -1]))[1]\n",
    "\n",
    "    conf = tf.add((_alpha * confidence_gathered),\n",
    "                  tf.reshape(tf.ones(shape=[tf.size(confidence_gathered)]), [-1, 1]))  \n",
    "        \n",
    "    regularizer_Y  =  tf.nn.l2_loss(tf.abs(Y['low_m']))\n",
    "    regularizer_B  =  tf.nn.l2_loss(tf.abs(B['basis_m']))    \n",
    "    \n",
    "    diff = tf.subtract(_true, _pred)\n",
    "    sq_diff = tf.square(diff)\n",
    "    confident_sq_diff = conf * sq_diff\n",
    "    sum_sq_diff = tf.reduce_sum(confident_sq_diff)\n",
    "    \n",
    "    mse = tf.divide(sum_sq_diff, _num) + _beta * (regularizer_Y + regularizer_B)\n",
    "    \n",
    "    opt = tf.train.GradientDescentOptimizer(learning_rate = lr_rat).minimize(mse)\n",
    "    \n",
    "    top_k = tf.to_int32(tf.divide(num_i, tf.constant(4)))\n",
    "    \n",
    "    # only makes sense to use percentile_rank if data is sparse and users watch less than 50% of videos\n",
    "    ordered_list_vals, ordered_list_idx = tf.nn.top_k(tf.reshape(_pred, [-1, num_i]), top_k)\n",
    "    \n",
    "    \n",
    "    \n",
    "    percentiles = (tf.to_float(tf.range(tf.size(ordered_list_idx))) \n",
    "                                     * tf.to_float(tf.divide(1, tf.size(ordered_list_idx))))\n",
    "    \n",
    "    idx_to_gather = tf.concat([tf.reshape(tf.transpose(tf.tile(input = [tf.range(num_u)],\n",
    "    multiples = [top_k, 1])), [-1, 1]), tf.reshape(ordered_list_idx, [-1, 1])], 1)\n",
    "    \n",
    "    r_ui = tf.gather_nd(params= tf.reshape(confidence_gathered, [-1, num_i]), indices= idx_to_gather)\n",
    "    \n",
    "    # accuracy\n",
    "    ranking = tf.divide(tf.reduce_sum(r_ui * percentiles), tf.reduce_sum(r_ui))\n",
    "    \n",
    "    return(mse, opt, ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_inst = tf_network_init()\n",
    "second_inst = tf_network_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.tf_network_init instance at 0x117ea1830>\n"
     ]
    }
   ],
   "source": [
    "print(first_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.tf_network_init instance at 0x117e26248>\n"
     ]
    }
   ],
   "source": [
    "print(second_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_path = 'missing_explicit/mat_fact_w_missing_values'\n",
    "path = 'missing_explicit/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'n_users' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-1e7563f94229>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_rank\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfirst_inst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0m_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_inst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_plh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_inst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mapp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_beta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msaver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriting_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_inst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_inst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0maccuracy_param\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-394adab2c282>\u001b[0m in \u001b[0;36minit_vars\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         self.Y = {'low_m': tf.Variable(tf.random_normal([n_users, _rank], mean=0.0,\n\u001b[0m\u001b[1;32m     19\u001b[0m         stddev=0.1) , name  =  'low_p', validate_shape = False),\n\u001b[1;32m     20\u001b[0m                 'low_b': tf.Variable(tf.random_normal([n_users, 1], mean=0.0,\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'n_users' is not defined"
     ]
    }
   ],
   "source": [
    "file_l = []\n",
    "for file in os.listdir('./missing_explicit'):\n",
    "    if fnmatch.fnmatch(file, 'run*'):\n",
    "        file_l.append(int(file[-2: ].strip('_'))) \n",
    "run = max(file_l) + 1\n",
    "for _rank in first_inst.rank:\n",
    "    _idx, _beta, _num = first_inst.init_plh()\n",
    "    Y, B = first_inst.init_vars()\n",
    "    app_x, mse, opt, rmse = main_network(Y, B, _beta, true_matrix, _num, _idx)\n",
    "    saver, summary_op, writer_1, writer_2, writing_method, sess = first_inst.init_network(first_inst, full_path, path, loss_param = mse ,accuracy_param= rmse)\n",
    "    train_network(full_path, path)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([1, 7, 13, 15 , 18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  7, 13, 15, 18])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percentile = []\n",
    "for i in range((len(a))):\n",
    "    percentile.append((i)*(100 / (len(a) -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 25, 50, 75, 100]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "44386997-0e84-45d6-a325-0fc196f62678",
    "theme": {
     "44386997-0e84-45d6-a325-0fc196f62678": {
      "backgrounds": {
       "dc7afa04-bf90-40b1-82a5-726e3cff5267": {
        "background-color": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "id": "dc7afa04-bf90-40b1-82a5-726e3cff5267"
       }
      },
      "id": "44386997-0e84-45d6-a325-0fc196f62678",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         197,
         226,
         245
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "a": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c"
       },
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 8
       },
       "h2": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "li": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3.25
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
       "font-family": "Lato",
       "font-size": 4
      }
     },
     "5066b0b0-49e9-4bb1-bedf-33db5955ab54": {
      "backgrounds": {
       "backgroundColor": {
        "background-color": "backgroundColor",
        "id": "backgroundColor"
       }
      },
      "id": "5066b0b0-49e9-4bb1-bedf-33db5955ab54",
      "palette": {
       "backgroundColor": {
        "id": "backgroundColor",
        "rgb": [
         34,
         34,
         34
        ]
       },
       "headingColor": {
        "id": "headingColor",
        "rgb": [
         256,
         256,
         256
        ]
       },
       "linkColor": {
        "id": "linkColor",
        "rgb": [
         66,
         175,
         250
        ]
       },
       "mainColor": {
        "id": "mainColor",
        "rgb": [
         256,
         256,
         256
        ]
       }
      },
      "rules": {
       "a": {
        "color": "linkColor"
       },
       "h1": {
        "color": "headingColor",
        "font-family": "Source Sans Pro",
        "font-size": 5.25
       },
       "h2": {
        "color": "headingColor",
        "font-family": "Source Sans Pro",
        "font-size": 4
       },
       "h3": {
        "color": "headingColor",
        "font-family": "Source Sans Pro",
        "font-size": 3.5
       },
       "h4": {
        "color": "headingColor",
        "font-family": "Source Sans Pro",
        "font-size": 3
       },
       "h5": {
        "color": "headingColor",
        "font-family": "Source Sans Pro"
       },
       "h6": {
        "color": "headingColor",
        "font-family": "Source Sans Pro"
       },
       "h7": {
        "color": "headingColor",
        "font-family": "Source Sans Pro"
       },
       "li": {
        "color": "mainColor",
        "font-family": "Source Sans Pro",
        "font-size": 6
       },
       "p": {
        "color": "mainColor",
        "font-family": "Source Sans Pro",
        "font-size": 6
       }
      },
      "text-base": {
       "color": "mainColor",
       "font-family": "Source Sans Pro",
       "font-size": 6
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
